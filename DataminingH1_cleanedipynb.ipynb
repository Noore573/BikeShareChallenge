{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uF3CEiZb4GtS"
      },
      "source": [
        "# **Loading libraries**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Xs-YTsgO8QA"
      },
      "outputs": [],
      "source": [
        "%pip install gdown\n",
        "%pip install tqdm scikit-learn\n",
        "%pip install geopandas\n",
        "%pip install geohash2\n",
        "%pip install folium\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import gdown\n",
        "import os\n",
        "import plotly.graph_objects as go\n",
        "import numpy as np\n",
        "from scipy.stats import gaussian_kde\n",
        "from google.colab import drive\n",
        "from math import radians, sin, cos, sqrt, atan2\n",
        "import geopandas as gpd\n",
        "from shapely.geometry import Point\n",
        "from sklearn.neighbors import BallTree\n",
        "from tqdm import tqdm\n",
        "import geohash2\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "\n",
        "\n",
        "import folium\n",
        "from folium.plugins import MarkerCluster\n",
        "\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I05pgLlnO8QA"
      },
      "outputs": [],
      "source": [
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZTfRsiq6CQa"
      },
      "source": [
        "# **Loading the data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9lConBSO8QB"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "downloading the dataset\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VkCADdlJzQGc"
      },
      "outputs": [],
      "source": [
        "folder_id = '1O3w5OKnS__hzlL8kTSfGCUc_iX8XNjEN'\n",
        "output_dir = 'Homework'\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "print(f\"Attempting to download content from folder ID: {folder_id} into {output_dir}\")\n",
        "try:\n",
        "    gdown.download_folder(id=folder_id, output=output_dir, quiet=False, use_cookies=False)\n",
        "    print(f\"\\nSuccessfully downloaded content to: /content/{output_dir}\")\n",
        "    print(\"You can now find the downloaded content in the 'downloaded_external_folder' directory in your Colab files browser.\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nAn error occurred during download: {e}\")\n",
        "    print(\"Please ensure the Google Drive folder is publicly accessible or shared with 'Anyone with the link can view'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SBxHrxew0knQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Load tabular data\n",
        "weather_df = pd.read_csv(\"Homework/data/Washington,DC,USA 2024-01-01 to 2024-12-31.csv\")\n",
        "trips_df = pd.read_parquet('Homework/data/daily-rent.parquet')\n",
        "\n",
        "# Load spatial parking zones\n",
        "parking_zones_gdf = gpd.read_file('Homework/data/Residential_and_Visitor_Parking_Zones.geojson')\n",
        "\n",
        "stations_df = pd.read_csv(\"Homework/data/Capital_Bikeshare_Locations.csv\")\n",
        "# Load spatial parking zones\n",
        "parking_zones_gdf = gpd.read_file('Homework/data/Residential_and_Visitor_Parking_Zones.geojson')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "Downloading the combined and modified dataset (for ease of use )\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Nxjq-QmE5b9K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# download the data straight\n",
        "import gdown as gdown\n",
        "# file_id = \"1eOCLRqXFnzvIz4I3S2uk0STHCk_Eg3pP\"\n",
        "file_id =\"114g7JYuZ00i864przAIJQYymib_5h6Qa\"\n",
        "output_file = \"trips_df.csv\"\n",
        "gdown.download(id=file_id, output=output_file, quiet=False)\n",
        "num_rows_to_read = 1_000_000\n",
        "\n",
        "print(f\"File downloaded to {output_file}\")\n",
        "trips_df = pd.read_csv(output_file,nrows=num_rows_to_read)\n",
        "trips_df.head()"
      ],
      "metadata": {
        "id": "nI0R9q-L5l8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trips_df.columns"
      ],
      "metadata": {
        "id": "7Q2rQL-n7LvW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SL1oTCjr6OFa"
      },
      "source": [
        "# **Cleaning & inspecting the data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Gt_DuEv4w9P"
      },
      "source": [
        "\n",
        "There is a problem with missing start/id , almost 20% of the data are null so we must find a way to fill these up\n",
        "\n",
        "**Try1 : spatial join**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "using lang and lati we can match it to the nearest station and then assign this id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h20Hhlhg1IFk"
      },
      "outputs": [],
      "source": [
        "trips_df = trips_df.dropna(subset=['end_lat', 'end_lng'])\n",
        "\n",
        "trips_df_cleaned=trips_df.drop_duplicates()\n",
        "trips_df_cleaned.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pw3RvCyR1T9h"
      },
      "outputs": [],
      "source": [
        "# EPSG:4326 = lat/lon\n",
        "trips_gdf = gpd.GeoDataFrame(\n",
        "    trips_df,\n",
        "    geometry=gpd.points_from_xy(trips_df['start_lng'], trips_df['start_lat']),\n",
        "    crs='EPSG:4326'\n",
        ")\n",
        "\n",
        "stations_gdf = gpd.GeoDataFrame(\n",
        "    stations_df,\n",
        "    geometry=gpd.points_from_xy(stations_df['LONGITUDE'], stations_df['LATITUDE']),\n",
        "    crs='EPSG:4326'\n",
        ")\n",
        "stations_gdf.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dA47hcEu1ldC"
      },
      "outputs": [],
      "source": [
        "# Find nearest station to each ride\n",
        "trips_with_nearest_station = gpd.sjoin_nearest(\n",
        "    trips_gdf, stations_gdf[['STATION_ID', 'geometry']],\n",
        "    how=\"left\", distance_col=\"distance\"\n",
        ")\n",
        "\n",
        "# Now we fill missing station_id with nearest one\n",
        "trips_df['start_station_id'] = trips_df['start_station_id'].fillna(\n",
        "    trips_with_nearest_station['STATION_ID']\n",
        ")\n",
        "# Create a mapping from STATION_ID to STATION_NAME\n",
        "id_to_name = stations_df.set_index('STATION_ID')['NAME'].to_dict()\n",
        "\n",
        "# Fill in missing start_station_name using start_station_id\n",
        "trips_df['start_station_name'] = trips_df['start_station_name'].fillna(\n",
        "    trips_df['start_station_id'].map(id_to_name)\n",
        ")\n",
        "trips_df_cleaned=trips_df.drop_duplicates()\n",
        "trips_df_cleaned.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8isYZzA4yfR"
      },
      "source": [
        "Repeating the process to end id and name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MIcXJiy95mU9"
      },
      "outputs": [],
      "source": [
        "trips_gdf_end = gpd.GeoDataFrame(\n",
        "    trips_df,\n",
        "    geometry=gpd.points_from_xy(trips_df['end_lng'], trips_df['end_lat']),\n",
        "    crs='EPSG:4326'\n",
        ")\n",
        "\n",
        "trips_with_nearest_end_station = gpd.sjoin_nearest(\n",
        "    trips_gdf_end, stations_gdf[['STATION_ID', 'geometry']],\n",
        "    how=\"left\", distance_col=\"end_distance\"\n",
        ")\n",
        "\n",
        "trips_df['end_station_id'] = trips_df['end_station_id'].fillna(\n",
        "    trips_with_nearest_end_station['STATION_ID']\n",
        ")\n",
        "trips_df['end_station_name'] = trips_df['end_station_name'].fillna(\n",
        "    trips_df['end_station_id'].map(id_to_name)\n",
        ")\n",
        "trips_df=trips_df.drop_duplicates()\n",
        "trips_df.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we will continue inspecting the rest of the data"
      ],
      "metadata": {
        "id": "zkda9AV_6sc4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "273sHOD85t0E"
      },
      "outputs": [],
      "source": [
        "stations_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yo2_a0EG6qbm"
      },
      "outputs": [],
      "source": [
        "stations_df=stations_df.drop_duplicates()\n",
        "stations_df.isna().sum()  # we dont need to drop null values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4BwUW136uQH"
      },
      "outputs": [],
      "source": [
        "weather_df=weather_df.drop_duplicates()\n",
        "weather_df.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TQGps8Rt62eU"
      },
      "outputs": [],
      "source": [
        "parking_zones_gdf.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XrMSX_Av6vdY"
      },
      "outputs": [],
      "source": [
        "parking_zones_gdf=parking_zones_gdf.drop_duplicates()\n",
        "parking_zones_gdf.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RhqxpEU267b0"
      },
      "outputs": [],
      "source": [
        "parking_zones_gdf = parking_zones_gdf.drop(columns=['CREATOR', 'CREATED','EDITOR','EDITED'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dhlna1xj9EeU"
      },
      "outputs": [],
      "source": [
        "parking_zones_gdf.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_WPYmtO8iLt"
      },
      "outputs": [],
      "source": [
        "parking_zones_gdf=parking_zones_gdf.drop_duplicates()\n",
        "parking_zones_gdf.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FHwlBbZ9ez-"
      },
      "source": [
        "# **PreProcessing the data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hhYVVGgM9mwY"
      },
      "outputs": [],
      "source": [
        "weather_df.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHgrh-3o-F1Y"
      },
      "outputs": [],
      "source": [
        "# first we make sure all the dates are in the same format (by checking the length)\n",
        "datetime_lengths = weather_df[\"datetime\"].astype(str).apply(len)\n",
        "print(datetime_lengths.value_counts())\n",
        "weather_df[\"date\"] = pd.to_datetime(weather_df[\"datetime\"])\n",
        "print(weather_df[\"date\"].dtype)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TU_XzGfm-3st"
      },
      "outputs": [],
      "source": [
        "trips_df[\"start_time\"] = pd.to_datetime(trips_df[\"started_at\"],format='mixed')\n",
        "trips_df[\"end_time\"] = pd.to_datetime(trips_df[\"ended_at\"],format='mixed')\n",
        "# ensuring that CRS is EPSG:4326\n",
        "if parking_zones_gdf.crs != \"EPSG:4326\":\n",
        "    parking_zones_gdf = parking_zones_gdf.to_crs(\"EPSG:4326\")\n",
        "# Spatial Join to Map Stations to Parking Zones\n",
        "# Spatial join: add zone info to each station\n",
        "stations_with_zone = gpd.sjoin(\n",
        "    stations_gdf,\n",
        "    parking_zones_gdf[[\"NAME\", \"geometry\"]],\n",
        "    how=\"left\",\n",
        "    predicate=\"within\"\n",
        ")\n",
        "# Rename column for clarity\n",
        "stations_with_zone = stations_with_zone.rename(columns={\"zone_name\": \"residential_zone\"})\n",
        "# Joining Weather Data\n",
        "# Extract date from start_time for weather join\n",
        "trips_df[\"date\"] = trips_df[\"start_time\"].dt.date\n",
        "weather_df[\"date\"] = weather_df[\"date\"].dt.date\n",
        "\n",
        "# Join weather by date\n",
        "trips_df = trips_df.merge(weather_df, on=\"date\", how=\"left\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQWxs96q_uH-"
      },
      "outputs": [],
      "source": [
        "trips_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4MHwqZPyBL_t"
      },
      "outputs": [],
      "source": [
        "trips_df[['start_station_id', 'end_station_id', 'start_station_name', 'end_station_name']].isnull().sum()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wnhDD_fQBZvY"
      },
      "outputs": [],
      "source": [
        "trips_df.head(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRUlFc1tO8QN"
      },
      "source": [
        "\n",
        "---\n",
        "B1\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48-Qa2HGpClZ"
      },
      "outputs": [],
      "source": [
        "# # B1\n",
        "\n",
        "# # From started_at\n",
        "# trips_df['start_year'] = trips_df['started_at'].dt.year\n",
        "# trips_df['start_month'] = trips_df['started_at'].dt.month\n",
        "# trips_df['start_day_num'] = trips_df['started_at'].dt.day\n",
        "# trips_df['start_day_name'] = trips_df['started_at'].dt.day_name()\n",
        "\n",
        "# # From ended_at\n",
        "# trips_df['end_year'] = trips_df['ended_at'].dt.year\n",
        "# trips_df['end_month'] = trips_df['ended_at'].dt.month\n",
        "# trips_df['end_day_num'] = trips_df['ended_at'].dt.day\n",
        "# trips_df['end_day_name'] = trips_df['ended_at'].dt.day_name()\n",
        "# trips_df.head(5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6HWUwZfBbaR"
      },
      "source": [
        "\n",
        "---\n",
        "B2\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trips_df['trip_duration_minutes'] = (trips_df['end_time'] - trips_df['start_time']).dt.total_seconds() / 60\n",
        "trips_df['trip_duration_minutes']=trips_df['trip_duration_minutes'].round(2)\n",
        "trips_df['trip_duration_minutes'].head(5)"
      ],
      "metadata": {
        "id": "z7eipZArwwpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The trip_duration_minutes problem**"
      ],
      "metadata": {
        "id": "SN-VHZhttU30"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trips_df['trip_duration_minutes'].describe()"
      ],
      "metadata": {
        "id": "DZ0TSaictSZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*we can clearly see that there is a problem with the tripd_durations, the min is a negative value and that is not right*"
      ],
      "metadata": {
        "id": "dugc51rytbJp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Show trips with negative or 0 duration\n",
        "invalid_durations = trips_df[trips_df['trip_duration_minutes'] <= 0]\n",
        "print(f\"Invalid rows: {len(invalid_durations)}\")\n",
        "invalid_durations[['ride_id', 'started_at', 'ended_at', 'trip_duration_minutes']].head()\n"
      ],
      "metadata": {
        "id": "ltwKRGertgvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter only valid trips\n",
        "trips_df = trips_df[trips_df['trip_duration_minutes'] > 0]\n",
        "trips_df['trip_duration_minutes'].describe()\n"
      ],
      "metadata": {
        "id": "W-wTEW_ZtjcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MC8yVG5pmu6"
      },
      "source": [
        "---\n",
        "B3\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trips_df['member_casual'].value_counts()"
      ],
      "metadata": {
        "id": "5iMUivT3_god"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yy1RkWaJodJF"
      },
      "outputs": [],
      "source": [
        "trips_df['rideable_type'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y5Q2d88_r7xx"
      },
      "outputs": [],
      "source": [
        "# Initialize base cost\n",
        "# Start with 0 cost\n",
        "trips_df['trip_cost'] = 0.0\n",
        "\n",
        "# Define fixed costs\n",
        "trips_df.loc[trips_df['member_casual'] == 'member', 'trip_cost'] = 3.95\n",
        "trips_df.loc[trips_df['member_casual'] == 'casual', 'trip_cost'] = 1.00\n",
        "\n",
        "# Add extra cost for duration\n",
        "# for members :\n",
        "# Create condition for member rides longer than 45 mins\n",
        "cond_member_extra = (trips_df['member_casual'] == 'member') & (trips_df['trip_duration_minutes'] > 45)\n",
        "\n",
        "# Electric bike extra for members\n",
        "trips_df.loc[cond_member_extra & (trips_df['rideable_type'] == 'electric_bike'), 'trip_cost'] += \\\n",
        "    (trips_df['trip_duration_minutes'] - 45) * 0.10\n",
        "\n",
        "# Classic bike extra for members\n",
        "trips_df.loc[cond_member_extra & (trips_df['rideable_type'] == 'classic_bike'), 'trip_cost'] += \\\n",
        "    (trips_df['trip_duration_minutes'] - 45) * 0.05\n",
        "# Electric bike for casuals\n",
        "cond_casual_electric = (trips_df['member_casual'] == 'casual') & (trips_df['rideable_type'] == 'electric_bike')\n",
        "trips_df.loc[cond_casual_electric, 'trip_cost'] += trips_df['trip_duration_minutes'] * 0.15\n",
        "\n",
        "# Classic bike for casuals\n",
        "cond_casual_classic = (trips_df['member_casual'] == 'casual') & (trips_df['rideable_type'] == 'classic_bike')\n",
        "trips_df.loc[cond_casual_classic, 'trip_cost'] += trips_df['trip_duration_minutes'] * 0.05\n",
        "# Add Central Business District (CBD) fee\n",
        "# Preparaing your geometry points\n",
        "# Create GeoDataFrame of start points\n",
        "trips_df['start_point'] = trips_df.apply(lambda row: Point(row['start_lng'], row['start_lat']), axis=1)\n",
        "trips_df['end_point'] = trips_df.apply(lambda row: Point(row['end_lng'], row['end_lat']), axis=1)\n",
        "# #  Load CBD Polygon\n",
        "CBD = gpd.read_file('Homework/data/DDOT_Central_Business_District.geojson')\n",
        "CBD = CBD.to_crs(epsg=4326)  # Ensures it's in WGS 84\n",
        "\n",
        "\n",
        "# Convert to GeoDataFrames with correct CRS\n",
        "start_gdf = gpd.GeoDataFrame(trips_df, geometry='start_point', crs='EPSG:4326').to_crs('EPSG:6933')\n",
        "end_gdf = gpd.GeoDataFrame(trips_df, geometry='end_point', crs='EPSG:4326').to_crs('EPSG:6933')\n",
        "\n",
        "# Load CBD polygon and project to EPSG:6933\n",
        "CBD = gpd.read_file('Homework/data/DDOT_Central_Business_District.geojson')\n",
        "CBD = CBD.to_crs(epsg=6933)\n",
        "cbd_polygon = CBD.geometry.unary_union  # Get full boundary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "306f9C9Nuh0x"
      },
      "outputs": [],
      "source": [
        "# # Spatial containment check\n",
        "# # Get the actual polygon geometry from CBD GeoDataFrame\n",
        "# cbd_polygon = CBD.geometry.unary_union  # safe in case of multipolygon\n",
        "\n",
        "# # Check for each row\n",
        "# trips_df['start_in_cbd'] = trips_df['start_point'].apply(lambda point: point.within(cbd_polygon))\n",
        "# trips_df['end_in_cbd'] = trips_df['end_point'].apply(lambda point: point.within(cbd_polygon))\n",
        "\n",
        "# # Final condition: start or end inside CBD\n",
        "# trips_df['in_cbd'] = trips_df['start_in_cbd'] | trips_df['end_in_cbd']\n",
        "# Check spatial containment in EPSG:6933\n",
        "trips_df['start_in_cbd'] = start_gdf['start_point'].apply(lambda point: point.within(cbd_polygon))\n",
        "trips_df['end_in_cbd'] = end_gdf['end_point'].apply(lambda point: point.within(cbd_polygon))\n",
        "\n",
        "# Final condition and cost update\n",
        "trips_df['in_cbd'] = trips_df['start_in_cbd'] | trips_df['end_in_cbd']\n",
        "trips_df.loc[trips_df['in_cbd'], 'trip_cost'] += 0.5\n",
        "trips_df['trip_cost'].head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pYgY5Pp2jR5W"
      },
      "outputs": [],
      "source": [
        "trips_df['trip_cost'].describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ck8sSCqNzuXo"
      },
      "source": [
        "*we can see a clear issue in the data ,  and super high values (4.3 mil in the max ) and std is very high (4837.62) , so we must identify this outliers and deal with them*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lE-WAd13voMS"
      },
      "outputs": [],
      "source": [
        "# High-cost trips\n",
        "high_cost = trips_df[trips_df['trip_cost'] > 1000].copy()\n",
        "print(high_cost[['ride_id', 'trip_duration_minutes', 'rideable_type', 'member_casual', 'trip_cost']])\n",
        "\n",
        "# Negative-cost trips\n",
        "neg_cost = trips_df[trips_df['trip_cost'] < 0].copy()\n",
        "print(neg_cost[['ride_id', 'trip_duration_minutes', 'rideable_type', 'member_casual', 'trip_cost']])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gRq1RuQcwwZT"
      },
      "outputs": [],
      "source": [
        "# Total rows\n",
        "total_rows = len(trips_df)\n",
        "\n",
        "# Define thresholds\n",
        "high_cost_threshold = 10000\n",
        "negative_cost_threshold = 0\n",
        "\n",
        "# Find outliers\n",
        "high_cost_outliers = trips_df[trips_df['trip_cost'] > high_cost_threshold]\n",
        "negative_cost_outliers = trips_df[trips_df['trip_cost'] < negative_cost_threshold]\n",
        "\n",
        "# Count\n",
        "num_high_cost = len(high_cost_outliers)\n",
        "num_negative_cost = len(negative_cost_outliers)\n",
        "total_outliers = num_high_cost + num_negative_cost\n",
        "\n",
        "# Percentages\n",
        "percent_high_cost = (num_high_cost / total_rows) * 100\n",
        "percent_negative_cost = (num_negative_cost / total_rows) * 100\n",
        "percent_total_outliers = (total_outliers / total_rows) * 100\n",
        "\n",
        "print(f\"High cost outliers: {num_high_cost} ({percent_high_cost:.2f}%)\")\n",
        "print(f\"Negative cost outliers: {num_negative_cost} ({percent_negative_cost:.2f}%)\")\n",
        "print(f\"Total outliers: {total_outliers} ({percent_total_outliers:.2f}%)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gHli55wtyMCY"
      },
      "outputs": [],
      "source": [
        "trips_df['trip_cost'].info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GzmRagLeyj4C"
      },
      "outputs": [],
      "source": [
        "# Drop outliers by reassigning the filtered DataFrame back to df\n",
        "trips_df = trips_df[(trips_df['trip_cost'] <= high_cost_threshold) & (trips_df['trip_cost'] >= negative_cost_threshold)]\n",
        "trips_df['trip_cost'].info()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jUSkTeWHyuOQ"
      },
      "outputs": [],
      "source": [
        "trips_df['trip_cost'].describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-inlm6X1UtR"
      },
      "source": [
        "---\n",
        "B4\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dFjJEIy_04-8"
      },
      "outputs": [],
      "source": [
        "stations_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tb4fPoBD1PaZ"
      },
      "outputs": [],
      "source": [
        "stations_df['CAPACITY'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "THTyaahb2BmM"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Basic histogram using Plotly\n",
        "fig = px.histogram(stations_df, x='CAPACITY', nbins=30, title='Distribution of Station Capacity')\n",
        "fig.update_layout(xaxis_title='Capacity', yaxis_title='Count', bargap=0.1)\n",
        "fig.show(config={'staticPlot': True})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UBzKGS5A4g2K"
      },
      "outputs": [],
      "source": [
        "# Drop NaNs\n",
        "capacity_data = stations_df['CAPACITY'].dropna()\n",
        "# Histogram\n",
        "hist_data = go.Histogram(x=capacity_data, nbinsx=30, name='Histogram', opacity=0.6)\n",
        "# Density Curve\n",
        "kde = gaussian_kde(capacity_data)\n",
        "x_vals = np.linspace(capacity_data.min(), capacity_data.max(), 1000)\n",
        "kde_data = go.Scatter(x=x_vals, y=kde(x_vals) * len(capacity_data) * (x_vals[1] - x_vals[0]),\n",
        "                      mode='lines', name='KDE Curve')\n",
        "\n",
        "# Plot both\n",
        "fig = go.Figure(data=[hist_data, kde_data])\n",
        "fig.update_layout(title='Capacity Distribution with KDE',\n",
        "                  xaxis_title='Capacity', yaxis_title='Count')\n",
        "# Example thresholds\n",
        "low_thresh = stations_df['CAPACITY'].quantile(0.30)\n",
        "high_thresh = stations_df['CAPACITY'].quantile(0.66)\n",
        "print(low_thresh,high_thresh)\n",
        "fig.add_vline(x=low_thresh, line_dash=\"dash\", line_color=\"green\", annotation_text=\"Small/Average\")\n",
        "fig.add_vline(x=high_thresh, line_dash=\"dash\", line_color=\"red\", annotation_text=\"Average/Large\")\n",
        "\n",
        "fig.show(config={'staticPlot': True})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ULXZ605f4sqp"
      },
      "outputs": [],
      "source": [
        "# Calculate the thresholds\n",
        "low_thresh = stations_df['CAPACITY'].quantile(0.33)\n",
        "high_thresh = stations_df['CAPACITY'].quantile(0.66)\n",
        "\n",
        "def classify_capacity(cap):\n",
        "    if cap <= low_thresh:\n",
        "        return 'Small'\n",
        "    elif cap <= high_thresh:\n",
        "        return 'Average'\n",
        "    else:\n",
        "        return 'Large'\n",
        "\n",
        "stations_df['STATION_SIZE'] = stations_df['CAPACITY'].apply(classify_capacity)\n",
        "stations_df['STATION_SIZE'].value_counts()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LssiAiXc6shB"
      },
      "outputs": [],
      "source": [
        "def classify_capacity(cap):\n",
        "    if cap <= 15:\n",
        "        return 'Small'\n",
        "    elif cap <= 25:\n",
        "        return 'Average'\n",
        "    else:\n",
        "        return 'Large'\n",
        "\n",
        "stations_df['STATION_SIZE'] = stations_df['CAPACITY'].apply(classify_capacity)\n",
        "print(stations_df['STATION_SIZE'].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J5_IiBmU7Npw"
      },
      "outputs": [],
      "source": [
        "\n",
        "fig = px.histogram(stations_df, x='CAPACITY', nbins=30, title='Station Capacity Distribution')\n",
        "fig.add_vline(x=15, line_dash=\"dash\", line_color=\"green\", annotation_text=\"Small/Average\")\n",
        "fig.add_vline(x=25, line_dash=\"dash\", line_color=\"red\", annotation_text=\"Average/Large\")\n",
        "\n",
        "fig.show(config={'staticPlot': True})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMBlw701c9vN"
      },
      "source": [
        "---\n",
        "B5\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fylKxgKMecgw"
      },
      "outputs": [],
      "source": [
        "Shuttle_Bus_Stops=pd.read_csv(\"Homework/data/Shuttle_Bus_Stops.csv\")\n",
        "Metro_Bus_Stops =pd.read_csv(\"Homework/data/Metro_Bus_Stops.csv\")\n",
        "Shuttle_Bus_Stops.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mIUA0TNYe2RO"
      },
      "outputs": [],
      "source": [
        "Metro_Bus_Stops['BSTP_LAT'].isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_buZ1x_CAVFQ"
      },
      "source": [
        "\n",
        "Approaches\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "| Approach                    | Time Complexity | Vectorized | Fast    |\n",
        "| --------------------------- | --------------- | ---------- | ------- |\n",
        "| Brute Force (Your original) | O(N Ã— M)        | âŒ No       | ðŸŒ Slow |\n",
        "| BallTree (New)              | O(N log M)      | âœ… Yes      | âš¡ Fast  |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_i2yvv2O8QX"
      },
      "source": [
        "Project all your coordinates to EPSG:6933\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iEGPg81slsNc"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Create start and end point geometries\n",
        "trips_df['start_point'] = trips_df.apply(lambda row: Point(row['start_lng'], row['start_lat']), axis=1)\n",
        "trips_df['end_point'] = trips_df.apply(lambda row: Point(row['end_lng'], row['end_lat']), axis=1)\n",
        "\n",
        "# Create GeoDataFrames\n",
        "gdf_start = gpd.GeoDataFrame(trips_df, geometry='start_point', crs='EPSG:4326').to_crs(epsg=6933)\n",
        "gdf_end = gpd.GeoDataFrame(trips_df, geometry='end_point', crs='EPSG:4326').to_crs(epsg=6933)\n",
        "\n",
        "# Add x/y columns\n",
        "trips_df['start_x'] = gdf_start.geometry.x\n",
        "trips_df['start_y'] = gdf_start.geometry.y\n",
        "trips_df['end_x'] = gdf_end.geometry.x\n",
        "trips_df['end_y'] = gdf_end.geometry.y\n",
        "\n",
        "\n",
        "# projecting   metro and shuttle station coordinates:\n",
        "\n",
        "# Convert station lat/lng to projected coordinates\n",
        "def project_coords(coords_list):\n",
        "    gdf = gpd.GeoDataFrame(geometry=[Point(lon, lat) for lat, lon in coords_list], crs='EPSG:4326')\n",
        "    gdf = gdf.to_crs(epsg=6933)\n",
        "    return np.array([(geom.x, geom.y) for geom in gdf.geometry])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cfj75bOenaPz"
      },
      "outputs": [],
      "source": [
        "# coords\n",
        "# Metro stop coordinates\n",
        "metro_coords = Metro_Bus_Stops[['BSTP_LAT', 'BSTP_LON']].dropna().values\n",
        "\n",
        "# Shuttle stop coordinates\n",
        "shuttle_coords = Shuttle_Bus_Stops[['LATITUDE', 'LONGITUDE']].dropna().values\n",
        "\n",
        "metro_coords_projected = project_coords(metro_coords)\n",
        "shuttle_coords_projected = project_coords(shuttle_coords)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UN48kQYPl5A0"
      },
      "outputs": [],
      "source": [
        "\n",
        "def euclidean_tree_batch(source_df, stop_coords, x_col, y_col, batch_size=10000):\n",
        "    tree = BallTree(stop_coords, metric='euclidean')\n",
        "\n",
        "    distances = []\n",
        "    n = len(source_df)\n",
        "    tqdm.pandas(desc=f\"Computing distances for {x_col}\")\n",
        "\n",
        "    for i in tqdm(range(0, n, batch_size), desc=\"Batch processing\", unit=\"batch\"):\n",
        "        batch = source_df.iloc[i:i+batch_size]\n",
        "        batch_points = batch[[x_col, y_col]].values\n",
        "\n",
        "        dists, _ = tree.query(batch_points, k=1)\n",
        "        distances.extend(dists.flatten().tolist())\n",
        "\n",
        "    return distances\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CvjyWh64l7Qd"
      },
      "outputs": [],
      "source": [
        "# Start â†’ Metro\n",
        "trips_df['start_nearest_metro_distance'] = euclidean_tree_batch(\n",
        "    trips_df, metro_coords_projected, 'start_x', 'start_y'\n",
        ")\n",
        "\n",
        "# End â†’ Metro\n",
        "trips_df['end_nearest_metro_distance'] = euclidean_tree_batch(\n",
        "    trips_df, metro_coords_projected, 'end_x', 'end_y'\n",
        ")\n",
        "\n",
        "# Start â†’ Shuttle\n",
        "trips_df['start_nearest_shuttle_distance'] = euclidean_tree_batch(\n",
        "    trips_df, shuttle_coords_projected, 'start_x', 'start_y'\n",
        ")\n",
        "\n",
        "# End â†’ Shuttle\n",
        "trips_df['end_nearest_shuttle_distance'] = euclidean_tree_batch(\n",
        "    trips_df, shuttle_coords_projected, 'end_x', 'end_y'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4bgJlGMAlPE"
      },
      "outputs": [],
      "source": [
        "trips_df['start_nearest_metro_distance'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CU88I8yln-bs"
      },
      "outputs": [],
      "source": [
        "trips_df['end_nearest_metro_distance'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZJ6s55lFYa_"
      },
      "outputs": [],
      "source": [
        "trips_df['start_nearest_shuttle_distance'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lF7cr7yTFYSV"
      },
      "outputs": [],
      "source": [
        "trips_df['end_nearest_shuttle_distance'].describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8yEENQZHLaS"
      },
      "source": [
        "we will drop outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LbLirzQrOwwC"
      },
      "outputs": [],
      "source": [
        "start_nearest_metro_distance_thr=1550\n",
        "end_nearest_metro_distance_thr=1600\n",
        "start_nearest_shuttle_distance_thr=23000\n",
        "end_nearest_shuttle_distance_thr=23200\n",
        "outliers=[]\n",
        "outliers.append(trips_df[trips_df['start_nearest_metro_distance'] > start_nearest_metro_distance_thr])\n",
        "outliers.append(trips_df[trips_df['end_nearest_metro_distance'] > end_nearest_metro_distance_thr])\n",
        "outliers.append(trips_df[trips_df['start_nearest_shuttle_distance'] > start_nearest_shuttle_distance_thr])\n",
        "outliers.append(trips_df[trips_df['end_nearest_shuttle_distance'] > start_nearest_shuttle_distance_thr])\n",
        "for i in outliers :\n",
        "  print(\"Outliers:\", len(i))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJME-JoxPGdW"
      },
      "outputs": [],
      "source": [
        "trips_df = trips_df[\n",
        "    (trips_df['start_nearest_metro_distance'] < start_nearest_metro_distance_thr) &\n",
        "    (trips_df['end_nearest_metro_distance'] < end_nearest_metro_distance_thr) &\n",
        "    (trips_df['start_nearest_shuttle_distance'] < start_nearest_shuttle_distance_thr) &\n",
        "    (trips_df['end_nearest_shuttle_distance'] < start_nearest_shuttle_distance_thr)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "oYitubZ64qKw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t3_w8Db_YRhh"
      },
      "outputs": [],
      "source": [
        "sampled_df = trips_df.sample(n=20000, random_state=50)\n",
        "\n",
        "\n",
        "cols = ['start_nearest_metro_distance', 'end_nearest_metro_distance',\n",
        "        'start_nearest_shuttle_distance', 'end_nearest_shuttle_distance']\n",
        "\n",
        "for col in cols:\n",
        "    fig = go.Figure(\n",
        "        data=[go.Histogram(\n",
        "            x=sampled_df[col],\n",
        "            nbinsx=100,\n",
        "            marker=dict(color='skyblue'),\n",
        "            opacity=0.75\n",
        "        )]\n",
        "    )\n",
        "\n",
        "    fig.update_layout(\n",
        "        title=col,\n",
        "        xaxis_title=col,\n",
        "        yaxis_title='Count (Log Scale)',\n",
        "        yaxis_type='log',\n",
        "        bargap=0.1,\n",
        "        width=800,\n",
        "        height=400\n",
        "    )\n",
        "    fig.show(config={'staticPlot':True})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smMf9ipl0yav"
      },
      "source": [
        "---\n",
        "B6\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4lXEKzGY2Lhs"
      },
      "outputs": [],
      "source": [
        "print(trips_df['start_point'].iloc[0], type(trips_df['start_point'].iloc[0]))\n",
        "print(trips_df['end_point'].iloc[0], type(trips_df['end_point'].iloc[0]))\n",
        "print(type(cbd_polygon))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HOAsnPfBp6Py"
      },
      "outputs": [],
      "source": [
        "# STEP 0: Make sure the CBD polygon is projected correctly\n",
        "CBD = CBD.to_crs(epsg=6933)\n",
        "cbd_polygon = CBD.geometry.iloc[0]  # assuming a single polygon\n",
        "# STEP 1: Create a GeoDataFrame from the trip points (start and end)\n",
        "# start_gdf = gpd.GeoDataFrame(trips_df, geometry=trips_df['start_point'], crs=\"EPSG:4326\")\n",
        "# end_gdf   = gpd.GeoDataFrame(trips_df, geometry=trips_df['end_point'], crs=\"EPSG:4326\")\n",
        "\n",
        "# Rebuild the point geometries from lat/lng in EPSG:4326\n",
        "start_gdf = gpd.GeoDataFrame(\n",
        "    trips_df,\n",
        "    geometry=gpd.points_from_xy(trips_df['start_lng'], trips_df['start_lat']),\n",
        "    crs=\"EPSG:4326\"\n",
        ")\n",
        "\n",
        "end_gdf = gpd.GeoDataFrame(\n",
        "    trips_df,\n",
        "    geometry=gpd.points_from_xy(trips_df['end_lng'], trips_df['end_lat']),\n",
        "    crs=\"EPSG:4326\"\n",
        ")\n",
        "\n",
        "\n",
        "# Project everything to EPSG:6933\n",
        "CBD = CBD.to_crs(epsg=6933)\n",
        "start_gdf = start_gdf.to_crs(epsg=6933)\n",
        "end_gdf = end_gdf.to_crs(epsg=6933)\n",
        "\n",
        "# CBD polygon (in same projection)\n",
        "cbd_polygon = CBD.geometry.unary_union\n",
        "# Check containment\n",
        "trips_df['start_in_cbd'] = start_gdf['geometry'].apply(lambda pt: cbd_polygon.contains(pt))\n",
        "trips_df['end_in_cbd']   = end_gdf['geometry'].apply(lambda pt: cbd_polygon.contains(pt))\n",
        "\n",
        "# Final result\n",
        "trips_df['in_cbd'] = trips_df['start_in_cbd'] | trips_df['end_in_cbd']\n",
        "trips_df['in_cbd'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3M_uabQt6Bza"
      },
      "source": [
        "---\n",
        "B7\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9oxDKxPlsm3r"
      },
      "outputs": [],
      "source": [
        "# --- Step 1: Compute the CBD centroid (already in EPSG:6933)\n",
        "cbd_centroid = cbd_polygon.centroid  # geometry in meters (EPSG:6933)\n",
        "\n",
        "# --- Step 2: Recreate end point GeoDataFrame and project to EPSG:6933\n",
        "end_gdf = gpd.GeoDataFrame(\n",
        "    trips_df,\n",
        "    geometry=gpd.points_from_xy(trips_df['end_lng'], trips_df['end_lat']),\n",
        "    crs=\"EPSG:4326\"\n",
        ").to_crs(epsg=6933)\n",
        "\n",
        "# --- Step 3: Compute Euclidean distance in meters\n",
        "trips_df['distance_to_cbd_m'] = end_gdf.geometry.distance(cbd_centroid)\n",
        "\n",
        "# --- Step 4: Set distance to None where start AND end are in the CBD\n",
        "mask = trips_df['start_in_cbd'] & trips_df['end_in_cbd']\n",
        "trips_df.loc[mask, 'distance_to_cbd_m'] = None\n",
        "\n",
        "# --- Step 5: Inspect result\n",
        "trips_df['distance_to_cbd_m'].describe()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Szoai97X63Qj"
      },
      "source": [
        "\n",
        "\n",
        "**Threasholding strategies**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wnOOXiY7I-C"
      },
      "source": [
        "elbow method"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_df = trips_df.sample(n=20000, random_state=50)\n",
        "\n",
        "# Extract the data\n",
        "data = sampled_df['distance_to_cbd_m'].dropna()\n",
        "\n",
        "# Create histogram trace\n",
        "hist = go.Histogram(\n",
        "    x=data,\n",
        "    nbinsx=100,\n",
        "    name='Histogram',\n",
        "    marker_color='lightblue',\n",
        "    opacity=0.75\n",
        ")\n",
        "\n",
        "# Create KDE line (manual since Plotly doesnâ€™t support KDE directly)\n",
        "kde = gaussian_kde(data)\n",
        "x_vals = np.linspace(data.min(), data.max(), 1000)\n",
        "kde_vals = kde(x_vals) * len(data) * (x_vals[1] - x_vals[0])  # scale to match histogram\n",
        "\n",
        "kde_trace = go.Scatter(\n",
        "    x=x_vals,\n",
        "    y=kde_vals,\n",
        "    mode='lines',\n",
        "    name='KDE',\n",
        "    line=dict(color='darkblue')\n",
        ")\n",
        "\n",
        "# Vertical reference lines\n",
        "vline1 = go.Scatter(\n",
        "    x=[2000, 2000],\n",
        "    y=[0, max(kde_vals)],\n",
        "    mode='lines',\n",
        "    name='2km Threshold',\n",
        "    line=dict(color='red', dash='dash')\n",
        ")\n",
        "\n",
        "vline2 = go.Scatter(\n",
        "    x=[2764, 2764],\n",
        "    y=[0, max(kde_vals)],\n",
        "    mode='lines',\n",
        "    name='Median',\n",
        "    line=dict(color='green', dash='dash')\n",
        ")\n",
        "\n",
        "# Create the figure\n",
        "fig = go.Figure(data=[hist, kde_trace, vline1, vline2])\n",
        "\n",
        "# Update layout\n",
        "fig.update_layout(\n",
        "    title='Distance to CBD at End of Trip',\n",
        "    xaxis_title='distance_to_cbd_m',\n",
        "    yaxis_title='Count',\n",
        "    width=800,\n",
        "    height=500,\n",
        "    legend=dict(x=0.7, y=0.95)\n",
        ")\n",
        "\n",
        "fig.show( config={'staticPlot':True})\n"
      ],
      "metadata": {
        "id": "XPKO880k6_k8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yvBXxgrW7IIf"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "i will choose this beacause looking at the histogram we can see the counts drops\n",
        "\"\"\"\n",
        "threshold = 2764\n",
        "# Apply binary classification\n",
        "trips_df['close_to_cbd'] = trips_df['distance_to_cbd_m'].apply(\n",
        "    lambda d: None if pd.isna(d) else d <= threshold\n",
        ")\n",
        "trips_df['close_to_cbd'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68oomfV78m6-"
      },
      "outputs": [],
      "source": [
        "print(trips_df['close_to_cbd'].isna().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ellq2QJVzAe3"
      },
      "source": [
        "---\n",
        "B8\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZVkChHv0YkX"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Washington, D.C. is roughly:\n",
        "\n",
        "~16 km (north-south)\n",
        "\n",
        "~13 km (east-west)\n",
        "\n",
        "So, a geohash precision of 5â€“8 is appropriate.\n",
        "\"\"\"\n",
        "def encode_geohashes(df, lat_col, lon_col, precisions):\n",
        "    for p in precisions:\n",
        "        col_name = f'geohash_p{p}'\n",
        "        df[col_name] = df.apply(lambda row: geohash2.encode(row[lat_col], row[lon_col], p), axis=1)\n",
        "    return df\n",
        "\n",
        "# Try precisions from 5 to 8\n",
        "precisions_to_test = [5, 6, 7, 8]\n",
        "trips_df = encode_geohashes(trips_df, 'start_lat', 'start_lng', precisions_to_test)\n",
        "for p in precisions_to_test:\n",
        "    print(f\"Precision {p}: {trips_df[f'geohash_p{p}'].nunique()} unique regions\")\n",
        "\"\"\"\n",
        "If the number is too small â†’ you're over-aggregating.\n",
        "\n",
        "If it's too big (e.g. thousands) â†’ too fine â†’ hard to summarize meaningfully.\n",
        "\"\"\"\n",
        "\n",
        "for p in precisions_to_test:\n",
        "    counts = trips_df[f'geohash_p{p}'].value_counts()\n",
        "    print(f\"Precision {p} â†’ median trips per geohash: {counts.median()}\")\n",
        "\"\"\"\n",
        "This tells you how balanced the spatial bins are.\n",
        "\n",
        "You ideally want 50â€“500 trips per cell.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShObmS0z4FJ1"
      },
      "source": [
        "| Precision | Median Trips per Geohash | Interpretation                                                     |\n",
        "| --------- | ------------------------ | ------------------------------------------------------------------ |\n",
        "| **5**     | 1761                     | âš ï¸ Too coarse â€” merges many neighborhoods into one.                |\n",
        "| **6**     | 196                      | âœ… Good balance â€” each area has enough trips for reliable analysis. |\n",
        "| **7**     | 7                        | âš ï¸ Very fine â€” may be too sparse for most practical summaries.     |\n",
        "| **8**     | 2                        | ðŸš« Too sparse â€” most areas will be noise or empty.                 |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g3yKdEI63oaL"
      },
      "outputs": [],
      "source": [
        "# we will choose 6\n",
        "trips_df['geohash_sector'] = trips_df['geohash_p6']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRZhifmX5KRC"
      },
      "source": [
        "---\n",
        "\n",
        "B9\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JpEGkPhx4RQ5"
      },
      "outputs": [],
      "source": [
        "# Group by Sector and Date\n",
        "# Assume you have a 'date' column (convert if needed)\n",
        "trips_df['date'] = pd.to_datetime(trips_df['date'])\n",
        "\n",
        "# Count trips per day per sector\n",
        "daily_counts = trips_df.groupby(['geohash_p6', 'date']).size().reset_index(name='trip_count')\n",
        "\n",
        "# Now compute average daily trips per geohash sector\n",
        "avg_daily_trips = daily_counts.groupby('geohash_p6')['trip_count'].mean().reset_index()\n",
        "avg_daily_trips.rename(columns={'trip_count': 'avg_daily_trips'}, inplace=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lctAtFgF5rwM"
      },
      "source": [
        "Choose Segmentation Method (for Red / Yellow / Gray)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfhDqYSj5nJs"
      },
      "source": [
        "\n",
        "| Method                         | Description                          | Pros             | Use Case             |\n",
        "| ------------------------------ | ------------------------------------ | ---------------- | -------------------- |\n",
        "| **Quantiles** (e.g., tertiles) | Divide into 3 equal-sized groups     | Simple, fair     | Balanced datasets    |\n",
        "| **Natural Breaks (Jenks)**     | Optimize separation between clusters | Data-aware       | Uneven distributions |\n",
        "| **KMeans Clustering (k=3)**    | Machine learning-based segmentation  | Optimal grouping | Large datasets       |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g__UfD5W5a6n"
      },
      "outputs": [],
      "source": [
        "# quantiles :\n",
        "# Assign labels based on quantiles\n",
        "quantiles = avg_daily_trips['avg_daily_trips'].quantile([1/3, 2/3])\n",
        "low_thresh = quantiles.iloc[0]\n",
        "high_thresh = quantiles.iloc[1]\n",
        "\n",
        "def classify_volume(val):\n",
        "    if val < low_thresh:\n",
        "        return 'gray'   # Low volume\n",
        "    elif val < high_thresh:\n",
        "        return 'yellow' # Medium volume\n",
        "    else:\n",
        "        return 'red'    # High volume\n",
        "\n",
        "avg_daily_trips['volume_segment'] = avg_daily_trips['avg_daily_trips'].apply(classify_volume)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Extract the data\n",
        "data = avg_daily_trips['avg_daily_trips'].dropna()\n",
        "\n",
        "# Histogram trace\n",
        "hist = go.Histogram(\n",
        "    x=data,\n",
        "    nbinsx=30,\n",
        "    marker_color='lightblue',\n",
        "    opacity=0.75,\n",
        "    name='Avg Daily Trips'\n",
        ")\n",
        "\n",
        "# Vertical threshold lines\n",
        "vline_low = go.Scatter(\n",
        "    x=[low_thresh, low_thresh],\n",
        "    y=[0, data.value_counts().max()],\n",
        "    mode='lines',\n",
        "    name='Low Threshold',\n",
        "    line=dict(color='gray', dash='dash')\n",
        ")\n",
        "\n",
        "vline_high = go.Scatter(\n",
        "    x=[high_thresh, high_thresh],\n",
        "    y=[0, data.value_counts().max()],\n",
        "    mode='lines',\n",
        "    name='High Threshold',\n",
        "    line=dict(color='orange', dash='dash')\n",
        ")\n",
        "\n",
        "# Combine into figure\n",
        "fig = go.Figure(data=[hist, vline_low, vline_high])\n",
        "\n",
        "# Update layout\n",
        "fig.update_layout(\n",
        "    title='Distribution of Avg Daily Trips per Geohash Sector',\n",
        "    xaxis_title='Avg Daily Trips',\n",
        "    yaxis_title='Count',\n",
        "    width=800,\n",
        "    height=500,\n",
        "    bargap=0.1\n",
        ")\n",
        "\n",
        "fig.show(config={'staticPlot':True})\n"
      ],
      "metadata": {
        "id": "SAYD3Ls1-Rpi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XYWaSyEE569w"
      },
      "outputs": [],
      "source": [
        "X = avg_daily_trips[['avg_daily_trips']].values\n",
        "\n",
        "kmeans = KMeans(n_clusters=3, random_state=42).fit(X)\n",
        "avg_daily_trips['kmeans_label'] = kmeans.labels_\n",
        "\n",
        "# Map to red/yellow/gray using sorted cluster means\n",
        "label_map = dict(zip(\n",
        "    np.argsort(kmeans.cluster_centers_.flatten()),\n",
        "    ['gray', 'yellow', 'red']\n",
        "))\n",
        "avg_daily_trips['kmeans_segment'] = avg_daily_trips['kmeans_label'].map(label_map)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eaBBJvFnZ81X"
      },
      "outputs": [],
      "source": [
        "avg_daily_trips.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2epWDpMGakGT"
      },
      "outputs": [],
      "source": [
        "trips_df['geohash_p6'].nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ONedOBCPcTl-"
      },
      "outputs": [],
      "source": [
        "# Merge segments into trips_df\n",
        "trips_df = trips_df.merge(\n",
        "    avg_daily_trips[['geohash_p6','volume_segment','kmeans_segment']],\n",
        "    on='geohash_p6',\n",
        "    how='left'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lDOdnzYxceA1"
      },
      "outputs": [],
      "source": [
        "trips_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c_gCbWosdaUt"
      },
      "outputs": [],
      "source": [
        "comparison = pd.crosstab(avg_daily_trips['volume_segment'], avg_daily_trips['kmeans_segment'])\n",
        "comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3eK2NYQkgpue"
      },
      "outputs": [],
      "source": [
        "trips_df['kmeans_segment'].value_counts()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2WSRw0iZhLjR"
      },
      "outputs": [],
      "source": [
        "trips_df['volume_segment'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fo1Nby-lsEf9"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "B10\n",
        "----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKSxW3W-dWCx"
      },
      "outputs": [],
      "source": [
        "trips_df['conditions'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jh1m4kfBfY8I"
      },
      "outputs": [],
      "source": [
        "def classify_weather(condition):\n",
        "    condition = condition.lower()  # lowercase for safety\n",
        "    if 'rain' in condition or 'snow' in condition:\n",
        "        return 'rainy'\n",
        "    elif 'overcast' in condition or 'cloudy' in condition:\n",
        "        return 'cloudy'\n",
        "    elif 'clear' in condition:\n",
        "        return 'sunny'\n",
        "    else:\n",
        "        return 'unknown'\n",
        "\n",
        "# Apply binning\n",
        "trips_df['weather_segment'] = trips_df['conditions'].apply(classify_weather)\n",
        "trips_df['weather_segment'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ep9rr_N9s9v_"
      },
      "source": [
        "---\n",
        "\n",
        "B11\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j_f0gqxJNym1"
      },
      "outputs": [],
      "source": [
        "sorted_ended_at_df = trips_df[['ended_at']].sort_values(by='ended_at')\n",
        "print(\"--- Sorted 'ended_at' DataFrame (first 5 rows) ---\")\n",
        "print(sorted_ended_at_df.head())\n",
        "print(\"\\n\")\n",
        "\n",
        "# --- Step 3: Find the earliest and latest dates ---\n",
        "earliest_date = sorted_ended_at_df['ended_at'].min()\n",
        "latest_date = sorted_ended_at_df['ended_at'].max()\n",
        "\n",
        "print(f\"The earliest date in 'ended_at' is: {earliest_date}\")\n",
        "print(f\"The latest date in 'ended_at' is: {latest_date}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37IY3SeYr1C1"
      },
      "outputs": [],
      "source": [
        "# Make sure 'ended_at' is datetime\n",
        "# trips_df['ended_at'] = pd.to_datetime(trips_df['ended_at'])\n",
        "trips_df['ended_at'] = pd.to_datetime(trips_df['ended_at'], format='mixed', errors='coerce')\n",
        "\n",
        "\n",
        "# Extract just the date (without time)\n",
        "trips_df['end_date'] = trips_df['ended_at'].dt.date\n",
        "daily_income_weather = trips_df.groupby(['end_date', 'weather_segment'])['trip_cost'].sum().reset_index()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NxfbTLjmtBDz"
      },
      "outputs": [],
      "source": [
        "# convert\n",
        "# Make sure end_date is datetime\n",
        "daily_income_weather['end_date'] = pd.to_datetime(daily_income_weather['end_date'])\n",
        "\n",
        "fig_long = px.line(\n",
        "    daily_income_weather,\n",
        "    x='end_date',\n",
        "    y='trip_cost',\n",
        "    color='weather_segment',\n",
        "    title='Daily Total Trip Cost by Weather Condition (Long Format)',\n",
        "    labels={'end_date': 'Date', 'trip_cost': 'Total Income', 'weather_segment': 'Weather'}\n",
        ")\n",
        "\n",
        "fig_long.update_layout(xaxis_title='Date', yaxis_title='Trip Cost', hovermode='x unified')\n",
        "fig_long.show(config={'staticPlot':True})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q6WfXRDRtHwQ"
      },
      "outputs": [],
      "source": [
        "# Pivot to wide format\n",
        "wide_df = daily_income_weather.pivot(index='end_date', columns='weather_segment', values='trip_cost').fillna(0)\n",
        "wide_df = wide_df.sort_index()\n",
        "\n",
        "# Build traces\n",
        "fig_wide = go.Figure()\n",
        "\n",
        "for condition in wide_df.columns:\n",
        "    fig_wide.add_trace(go.Scatter(\n",
        "        x=wide_df.index,\n",
        "        y=wide_df[condition],\n",
        "        mode='lines',\n",
        "        name=condition\n",
        "    ))\n",
        "\n",
        "fig_wide.update_layout(\n",
        "    title='Daily Total Trip Cost by Weather Condition (Wide Format)',\n",
        "    xaxis_title='Date',\n",
        "    yaxis_title='Trip Cost',\n",
        "    hovermode='x unified',\n",
        "    template='plotly_white',\n",
        "    legend_title='Weather'\n",
        ")\n",
        "\n",
        "fig_wide.show(config={'staticPlot':True})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMDgJxs8OXx_"
      },
      "source": [
        "Which one is better for our problem  ?\n",
        "answer here :"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBXs3HzQO-wt"
      },
      "source": [
        "---\n",
        "B12\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bN5x_9uTt2RV"
      },
      "outputs": [],
      "source": [
        "# feature 1 : rush_hour\n",
        "# Indicates if the ride occurred during typical commuting hours (7â€“10 AM or 4â€“7 PM).\n",
        "trips_df['start_time'] = pd.to_datetime(trips_df['start_time'], errors='coerce')\n",
        "\n",
        "trips_df['rush_hour'] = (\n",
        "    trips_df['start_time'].dt.hour.between(7, 10) |\n",
        "    trips_df['start_time'].dt.hour.between(16, 19)\n",
        ").astype(int)\n",
        "trips_df['rush_hour'].value_counts()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQtxwZZnPxnT"
      },
      "outputs": [],
      "source": [
        "# feature 2 : hour_segment\n",
        "# Categorize ride start times into broader buckets.\n",
        "def get_hour_segment(hour):\n",
        "    if 5 <= hour < 12:\n",
        "        return 'Morning'\n",
        "    elif 12 <= hour < 17:\n",
        "        return 'Midday'\n",
        "    elif 17 <= hour < 21:\n",
        "        return 'Evening'\n",
        "    else:\n",
        "        return 'Night'\n",
        "\n",
        "trips_df['hour_segment'] = trips_df['start_time'].dt.hour.apply(get_hour_segment)\n",
        "trips_df['hour_segment'].value_counts()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZiVY5Od0QKAe"
      },
      "outputs": [],
      "source": [
        "# feature 3 : is_weekend\n",
        "# Helps spot usage patterns on weekends vs weekdays.\n",
        "trips_df['is_weekend'] = trips_df['start_time'].dt.dayofweek >= 5\n",
        "trips_df['is_weekend'] = trips_df['is_weekend'].astype(int)\n",
        "trips_df['is_weekend'].value_counts()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ARUwuaWYQWnr"
      },
      "outputs": [],
      "source": [
        "# feature 4 : ride_density_zone\n",
        "# Based on start locationâ€™s proximity to popular stations (e.g., CBD or metro/shuttle stations).\n",
        "trips_df['ride_density_zone'] = np.where(\n",
        "    trips_df['start_nearest_metro_distance'] < 0.5, 'High Density', 'Low Density'\n",
        ")\n",
        "trips_df['ride_density_zone'].value_counts()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKjV0usaQvj8"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Save the stations_df DataFrame to a CSV file\n",
        "# Define the path in your Google Drive\n",
        "output_path = '/content/drive/My Drive/BikeShare/trips_df_9-6.csv'\n",
        "\n",
        "# Ensure the directory exists (optional, but good practice)\n",
        "import os\n",
        "output_dir = os.path.dirname(output_path)\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "# Save the DataFrame\n",
        "trips_df.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"trips_df successfully saved to {output_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49oBoftHUUaG"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "#**EDA**\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "Sampling the data\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "tTOhRmjguH-c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Full filtered data stats\n",
        "# print(\"Full Data:\")\n",
        "# print(trips_df['trip_duration_minutes'].describe())\n",
        "\n",
        "# Sampled data stats\n",
        "sampled_df = trips_df.sample(n=20000, random_state=50)\n",
        "# print(\"\\nSampled Data:\")\"\"\n",
        "# print(sampled_df['trip_duration_minutes'].describe())\n"
      ],
      "metadata": {
        "id": "ABgwYinmuLkR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxL-4ceXUYhn"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "# A )\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4cwZZ30VTEp_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4GFM4egUk3o"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "# B)\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wK_yKo3mUtU4"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "Task 1\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_mATqblU0nY"
      },
      "source": [
        "| Method                     | Formula                         | Notes                               |\n",
        "| -------------------------- | ------------------------------- | ----------------------------------- |\n",
        "| **Sturgesâ€™ Rule**          | `bins = ceil(log2(n) + 1)`      | Good for small to medium-sized data |\n",
        "| **Freedmanâ€“Diaconis Rule** | `bin_width = 2 * IQR / n^(1/3)` | Good for skewed data or outliers    |\n",
        "| **Square Root Rule**       | `bins = sqrt(n)`                | Simple and often a good baseline    |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L8HlhefNL3gb"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Use the sampled dataframe to avoid memory issues\n",
        "durations = sampled_df['trip_duration_minutes']\n",
        "\n",
        "# Freedmanâ€“Diaconis rule for bin width\n",
        "q25, q75 = np.percentile(durations, [25, 75])\n",
        "iqr = q75 - q25\n",
        "n = len(durations)\n",
        "bin_width = 2 * iqr / (n ** (1/3))\n",
        "bin_count = int(np.ceil((durations.max() - durations.min()) / bin_width))\n",
        "\n",
        "print(f\"Suggested bin count: {bin_count}\")\n",
        "\n",
        "# Static histogram\n",
        "fig = go.Figure(\n",
        "    data=[go.Histogram(\n",
        "        x=durations,\n",
        "        nbinsx=bin_count,\n",
        "        marker_color='blue',\n",
        "        opacity=1.0\n",
        "    )]\n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "    title=\"Distribution of Trip Duration (in Minutes)\",\n",
        "    xaxis_title=\"Trip Duration (minutes)\",\n",
        "    yaxis_title=\"Frequency\",\n",
        "    bargap=0.05,\n",
        "    template='simple_white'\n",
        ")\n",
        "\n",
        "fig.show(config={'staticPlot': True})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xG-L58E8ESel"
      },
      "source": [
        "test without outliers :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88-AjkyzEU6m"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# Choose your cutoff (in minutes)\n",
        "cutoff = 1440  # Modify as needed\n",
        "\n",
        "# Use the sampled dataframe to avoid memory issues\n",
        "durations = sampled_df['trip_duration_minutes']\n",
        "\n",
        "# Freedmanâ€“Diaconis rule for bin width\n",
        "q25, q75 = np.percentile(durations, [25, 75])\n",
        "iqr = q75 - q25\n",
        "n = len(durations)\n",
        "bin_width = 2 * iqr / (n ** (1/3))\n",
        "bin_count = int(np.ceil((durations.max() - durations.min()) / bin_width))\n",
        "\n",
        "print(f\"Suggested bin count: {bin_count}\")\n",
        "\n",
        "# Create the histogram\n",
        "fig = go.Figure()\n",
        "\n",
        "# Histogram of durations\n",
        "fig.add_trace(go.Histogram(\n",
        "    x=durations,\n",
        "    nbinsx=bin_count,\n",
        "    marker_color='blue',\n",
        "    opacity=1.0,\n",
        "    name=\"Trip Durations\"\n",
        "))\n",
        "\n",
        "# Vertical cutoff line\n",
        "fig.add_trace(go.Scatter(\n",
        "    x=[cutoff, cutoff],\n",
        "    y=[0, durations.value_counts().max()],\n",
        "    mode=\"lines\",\n",
        "    line=dict(color=\"red\", width=2, dash=\"dash\"),\n",
        "    name=f\"Cutoff = {cutoff} min\"\n",
        "))\n",
        "\n",
        "fig.update_layout(\n",
        "    title=\"Distribution of Trip Duration (in Minutes) with Cutoff\",\n",
        "    xaxis_title=\"Trip Duration (minutes)\",\n",
        "    yaxis_title=\"Frequency\",\n",
        "    bargap=0.05,\n",
        "    template='simple_white'\n",
        ")\n",
        "\n",
        "fig.show(config={'staticPlot': True})\n",
        "\n",
        "# Count how many trips exceed the cutoff\n",
        "sampled_exceed = (sampled_df['trip_duration_minutes'] > cutoff).sum()\n",
        "full_exceed = (trips_df['trip_duration_minutes'] > cutoff).sum()\n",
        "\n",
        "print(f\"Trips in sampled_df exceeding {cutoff} minutes: {sampled_exceed}\")\n",
        "print(f\"Trips in trips_df exceeding {cutoff} minutes: {full_exceed}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q78CKfIqMzVr"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "Task2\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sCw3707wXM-6"
      },
      "outputs": [],
      "source": [
        "# Use the original (not divided) trip durations\n",
        "durations = sampled_df['trip_duration_minutes']\n",
        "types = sampled_df['rideable_type']\n",
        "\n",
        "# Build the box plot grouped by rideable_type\n",
        "fig = go.Figure()\n",
        "\n",
        "# Loop through each rideable type and add a box\n",
        "for bike_type in sampled_df['rideable_type'].unique():\n",
        "    fig.add_trace(go.Box(\n",
        "        y=sampled_df[sampled_df['rideable_type'] == bike_type]['trip_duration_minutes'],\n",
        "        name=bike_type,\n",
        "        boxpoints='outliers',  # show outliers only\n",
        "        marker_color='green',\n",
        "        line_color='black',\n",
        "        opacity=0.8\n",
        "    ))\n",
        "\n",
        "fig.update_layout(\n",
        "    title=\"Box Plot of Trip Duration by Rideable Type\",\n",
        "    yaxis_title=\"Trip Duration (minutes)\",\n",
        "    xaxis_title=\"Rideable Type\",\n",
        "    template='simple_white'\n",
        ")\n",
        "\n",
        "# Render statically to avoid Colab issues\n",
        "fig.show(config={'staticPlot': True})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQ5QqIOIM4mz"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "Task3\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1ZEPTa6MwH-"
      },
      "outputs": [],
      "source": [
        "trips_df['member_casual'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lpLjgXVjMiwf"
      },
      "outputs": [],
      "source": [
        "# Use the original (not divided) trip durations\n",
        "durations = sampled_df['trip_duration_minutes']\n",
        "types = sampled_df['member_casual']\n",
        "\n",
        "# Build the box plot grouped by rideable_type\n",
        "fig = go.Figure()\n",
        "\n",
        "# Loop through each rideable type and add a box\n",
        "for bike_type in sampled_df['rideable_type'].unique():\n",
        "    fig.add_trace(go.Box(\n",
        "        y=sampled_df[sampled_df['rideable_type'] == bike_type]['trip_duration_minutes'],\n",
        "        name=bike_type,\n",
        "        boxpoints='outliers',  # show outliers only\n",
        "        marker_color='green',\n",
        "        line_color='black',\n",
        "        opacity=0.8\n",
        "    ))\n",
        "\n",
        "fig.update_layout(\n",
        "    title=\"Box Plot of Trip Duration by Rideable Type\",\n",
        "    yaxis_title=\"Trip Duration (minutes)\",\n",
        "    xaxis_title=\"Rideable Type\",\n",
        "    template='simple_white'\n",
        ")\n",
        "\n",
        "# Render statically to avoid Colab issues\n",
        "fig.show(config={'staticPlot': True})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qeo_Z_xBDA9A"
      },
      "source": [
        "dealing with outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CzYIZTBODD3w"
      },
      "outputs": [],
      "source": [
        "# Compute IQR\n",
        "Q1 = sampled_df['trip_duration_minutes'].quantile(0.25)\n",
        "Q3 = sampled_df['trip_duration_minutes'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "# Define outlier bounds\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "print(f\"Lower Bound: {lower_bound}\")\n",
        "print(f\"Upper Bound: {upper_bound}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zs0wC5GyObKO"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "Task4\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "svFx42HGM6BK"
      },
      "outputs": [],
      "source": [
        "# Count Trips Longer Than One Day\n",
        "\n",
        "# Define threshold: 1 day = 1440 minutes\n",
        "one_day_minutes = 1440\n",
        "\n",
        "# Filter trips longer than 1 day\n",
        "long_trips_df = sampled_df[sampled_df['trip_duration_minutes'] > one_day_minutes]\n",
        "long_sampled_df = sampled_df[sampled_df['trip_duration_minutes'] > one_day_minutes]\n",
        "# Show how many there are\n",
        "print(f\"Total number of trips longer than 1 day in full data: {len(long_trips_df)}\")\n",
        "print(f\"Total number of trips longer than 1 day in sampled data: {len(long_sampled_df)}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Combine start and end station counts for long trips\n",
        "\n",
        "\n",
        "start_counts = long_trips_df['start_station_id'].value_counts()\n",
        "end_counts = long_trips_df['end_station_id'].value_counts()\n",
        "\n",
        "# Combine them into a single Series\n",
        "total_counts = start_counts.add(end_counts, fill_value=0).astype(int)\n",
        "\n",
        "# Get station info: name and location\n",
        "stations = sampled_df[['start_station_id', 'start_station_name', 'start_lat', 'start_lng']].drop_duplicates()\n",
        "stations = stations.rename(columns={\n",
        "    'start_station_id': 'station_id',\n",
        "    'start_station_name': 'station_name',\n",
        "    'start_lat': 'lat',\n",
        "    'start_lng': 'lng'\n",
        "})\n",
        "\n",
        "# Merge with counts\n",
        "stations['long_trip_count'] = stations['station_id'].map(total_counts).fillna(0).astype(int)\n",
        "\n",
        "# Filter stations with at least 1 long trip\n",
        "stations = stations[stations['long_trip_count'] > 0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CUi2VkSdPsTG"
      },
      "outputs": [],
      "source": [
        "stations['long_trip_count']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cVJdaV5bO0sH"
      },
      "outputs": [],
      "source": [
        "# Center the map on Washington DC\n",
        "m = folium.Map(location=[38.9072, -77.0369], zoom_start=12, tiles='cartodbpositron')\n",
        "\n",
        "# Optional: cluster points\n",
        "marker_cluster = MarkerCluster().add_to(m)\n",
        "\n",
        "# Add stations to the map\n",
        "for _, row in stations.iterrows():\n",
        "    folium.CircleMarker(\n",
        "        location=[row['lat'], row['lng']],\n",
        "        radius=3 + row['long_trip_count']**0.5,  # scale marker size\n",
        "        color='darkred',\n",
        "        fill=True,\n",
        "        fill_color='crimson',\n",
        "        fill_opacity=0.7,\n",
        "        popup=f\"{row['station_name']}<br>Trips > 1 day: {row['long_trip_count']}\"\n",
        "    ).add_to(marker_cluster)\n",
        "\n",
        "# Show the map\n",
        "m\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_xzP7hhWPPbI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehZahS1cJPcY"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "# C)\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "Task1\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "oNXnXa997gP_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(sampled_df['trip_cost'].unique())\n",
        "\n",
        "sampled_df['start_time'] = pd.to_datetime(sampled_df['start_time'])"
      ],
      "metadata": {
        "id": "hAYaUcZQ7rRA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "\n",
        "# cost Histogram\n",
        "fig = px.histogram(sampled_df, x='trip_cost', nbins=141, title='distrupation of trips cost')\n",
        "fig.show()\n",
        "\n",
        "# cost Boxplot\n",
        "fig = px.box(sampled_df, y='trip_cost', title='Boxplot of trips cost')\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "3Av2vDQ_Cw6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Ù†Ù„Ø§Ø­Ø¸ Ø§Ù† Ø§ØºÙ„Ø¨ Ø§Ù„Ø¯Ø§ØªØ§ Ù…ØªÙˆØ²Ø¹Ø© Ø¨ÙŠÙ† Ø§Ù„0 - ÙˆØ§Ù„10 Ø¯ÙˆÙ„Ø§Ø± Ø¨ÙƒØ«Ø±Ø© ÙˆØ§Ù† Ø§Ù„Ù‚Ù…Ø© Ø¨ÙŠÙ† 3.5 Ùˆ4 ÙˆÙ‡Ø°Ø§ ÙŠØ¯Ù„ Ø¹Ù„Ù‰ Ø§Ù†Ù‡ ÙŠÙˆØ¬Ø¯ Ø§Ù„ÙƒØ«ÙŠØ± Ù…Ù† Ø§Ù„Ù†Ø§Ø³ Ù…Ø´ØªØ±ÙƒØ© ÙˆØ§ØºÙ„Ø¨ Ø§Ù„Ø±Ø­Ù„ Ù„Ø§ ØªØªØ¬Ø§ÙˆØ² Ø§Ù„45 Ø¯Ù‚ÙŠÙ‚Ø©\n",
        "\n",
        "- ÙˆØ§ÙŠØ¶Ø§ ÙŠÙˆØ¬Ø¯ Ù‚ÙŠÙ… Ø§ÙƒØ¨Ø± ØµØ­ÙŠØ­ Ø§Ù†Ù‡Ø§ Ù†Ø§Ø¯Ø±Ø© ÙˆÙ„ÙƒÙ†Ù‡Ø§ Ù…ØªÙˆØ²Ø¹Ø© ÙˆÙ‡Ø°Ø§ ÙŠØ¯Ù„ Ø§Ù†Ù‡ ÙŠÙˆØ¬Ø¯ Ø§Ø´Ø®Ø§Øµ ØªØ§Ø®Ø°Ù‡Ø§ Ù„Ù…Ø³Ø§ÙØ§Øª ÙƒØ¨ÙŠØ±Ø© ÙˆÙ„ÙƒÙ†Ù‡Ø§ Ù‚Ù„ÙŠÙ„Ø©  \n",
        "- ØºØ§Ù„Ø¨Ø§ Ø§Ù„Ø±Ø­Ù„ Ø°Ø§Øª ØªÙƒÙ„ÙØ© Ø§Ù„Ø¹Ø§Ù„ÙŠØ© Ø§Ø´Ø®Ø§Øµ ØºÙŠØ± Ù…Ø´ØªØ±ÙƒÙŠÙ† Ø¨Ø§Ù„Ø§Ø¶Ø§ÙØ© Ø§Ù„Ù‰ Ø§Ù†Ù‡Ù… Ù‚Ø¯ ÙŠÙƒÙˆÙ†ÙˆÙ† Ù…Ø±Ø© ÙˆØ§Ø­Ø¯Ø© ÙÙ‚Ø· ÙŠØ³ØªØ®Ø¯Ù…ÙˆÙ† Ø§Ù„Ø¯Ø±Ø§Ø¬Ø§Øª ÙˆÙ„Ø§ ÙŠØ¹ÙˆØ¯ÙˆÙ† Ø§Ù„Ù‰ Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡Ø§ Ø¨Ø¹Ø¯ ØªØ¬Ø±Ø¨Ø© Ø§Ù„Ø®Ø¯Ù…Ø© ÙˆØ±Ø¤ÙŠØ© Ø§Ù„Ø³Ø¹Ø±\n"
      ],
      "metadata": {
        "id": "VAoAZJ7nSAaW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "task2\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "F-Memz3ealR-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.scatter(sampled_df, x='trip_duration_minutes', y='trip_cost', trendline='ols',title='the realtion between duration and cost')\n",
        "fig.show()\n",
        "# lowess', 'rolling', 'ewm', 'expanding', 'ols'"
      ],
      "metadata": {
        "id": "IEWmiWYslF82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„ØªÙŠ Ù‚ÙŠÙ…ØªÙ‡Ø§ Ù‚Ø±ÙŠØ¨Ø© Ù…Ù† Ø§Ù„ØµÙØ± ÙƒÙˆÙ‚Øª Ù‡ÙŠ ØªÙ…Ø«Ù„ Ø§Ù„Ø§Ø¹Ø¶Ø§Ø¡ Ø§Ù„ØªÙŠ Ù„Ø¯ÙŠÙ‡Ù… Ø§Ø´ØªØ±Ø§Ùƒ ÙˆÙ„Ù… ÙŠØªØ¬Ø§ÙˆØ²ÙˆØ§ Ø§Ù„45 Ø¯Ù‚ÙŠÙ‚Ø© ÙˆÙƒÙ…Ø§ Ù†Ù„Ø§Ø­Ø¸ Ù‡Ù… ÙƒØ«Ø±\n",
        "*   ÙˆÙ„Ø¯ÙŠÙ†Ø§ Ø«Ù„Ø§Ø« ØªÙˆØ²Ø¹Ø§Øª Ù„Ù„Ù†Ù‚Ø§Ø· ÙˆØ°Ù„Ùƒ ÙŠØ¹ÙˆØ¯ Ø¨Ø³Ø¨Ø¨ Ø§Ù„Ø§Ø´ØªØ±Ø§Ùƒ Ø§Ùˆ Ø¹Ø¯Ù…Ù‡ ÙˆØ­ØªÙ‰ Ù…Ø±ÙˆØ±Ù‡ Ø¨Ø§Ù„Ù…Ù†Ø·Ù‚Ø© Ø§Ù„ØªØ¬Ø§Ø±ÙŠØ©\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cYQFqMY09kTk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "Task3\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uuKHRBScZugs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.scatter(sampled_df, x='temp', y='trip_cost', color='member_casual',\n",
        "                 title='cost vs temperatur ')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "SVDDsUqjHqkQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Ø§ØºÙ„Ø¨ Ø§Ù„Ø±Ø­Ù„Ø§Øª ØªÙƒÙˆÙ† Ø¨ÙŠÙ† 5 Ø¯Ø±Ø¬Ø§Øª ÙˆØ§Ù„20 Ø¯Ø±Ø¬Ø©\n",
        "*   Ø¹Ù†Ø¯Ù…Ø§ ØªÙƒÙˆÙ† Ø¯Ø±Ø¬Ø© Ø§Ù„Ø­Ø±Ø§Ø±Ø© ÙÙˆÙ‚ Ø§Ù„20 Ù†Ù„Ø§Ø­Ø¸ Ø§Ù† Ø¹Ø¯Ø¯ Ø§Ù„Ø±Ø­Ù„Ø§Øª Ù‚Ù„ÙŠÙ„\n",
        "* ÙƒÙ…Ø§ Ù†Ù„Ø§Ø­Ø¸ Ø§ØºÙ„Ø¨ Ø±Ø­Ù„ Ø§Ù„Ù…Ø´ØªØ±ÙƒÙŠÙ† Ø§Ù„ÙƒÙ„ÙØ© ØºØ§Ù„Ø¨Ø§ Ø§Ù‚Ù„ Ù…Ù† 10 Ø¯ÙˆÙ„Ø§Ø±\n",
        "* Ù†Ù„Ø§Ø­Ø¸ Ø§Ù† Ø§ØºÙ„Ø¨ Ø§Ù„ÙƒÙ„Ù Ø§Ù„Ø¹Ø§Ù„ÙŠØ© Ù…Ù† Ø§Ù„ØºÙŠØ± Ø§Ù„Ù…Ø´ØªØ±ÙƒÙŠÙ†\n",
        "* Ù„Ø§ÙŠÙˆØ¬Ø¯ Ø¹Ù„Ø§Ù‚Ø© ÙˆØ§Ø¶Ø­Ø© Ø¨ÙŠÙ† Ø¯Ø±Ø¬Ø© Ø§Ù„Ø­Ø±Ø§Ø±Ø© ÙˆØ§Ù„ØªÙƒÙ„ÙØ© Ù„ÙƒÙ† ÙŠÙ…ÙƒÙ† Ø§Ù„ÙÙˆÙ„ Ø§Ù† Ø¨ÙŠÙ† Ø§Ù„ 5 -15 ÙŠÙ…ÙƒÙ† Ù„Ù„Ù†Ø§Ø³ Ø§Ù† ØªØ°Ù‡Ø¨ Ø¨Ø±Ø­Ù„Ø§Øª Ø£Ø·ÙˆÙ„\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TziBT-sqW833"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "Task4\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "323sHquUZsBm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "daily_rev = sampled_df.groupby(sampled_df['start_time'].dt.date)['trip_cost'].sum().reset_index(name='revenue')\n",
        "fig = px.line(daily_rev, x='start_time', y='revenue', title='daily incomes')\n",
        "fig.show()\n",
        "\n",
        "sampled_df['week'] = sampled_df['start_time'].dt.isocalendar().week\n",
        "weekly_rev = sampled_df.groupby('week')['trip_cost'].sum().reset_index(name='revenue')\n",
        "fig = px.line(weekly_rev, x='week', y='revenue', title='weekly incomes')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "DqwZvFevaXbT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„Ù„Ø§ÙŠØ±Ø§Ø¯Ø§Øª Ø§Ù„ÙŠÙˆÙ…Ø¨Ø© Ù†Ù„Ø§Ø­Ø¸ ÙˆØ¬ÙˆØ¯ Ø¨ÙŠÙ† Ù‡Ø¨ÙˆØ· ÙˆØµØ¹ÙˆØ¯ ÙˆÙ…Ø¹ Ø§Ø³ØªÙ…Ø±Ø§Ø± Ø§Ù„Ø§ÙŠØ§Ù… Ù†Ù„Ø§Ø­Ø¸ Ø²ÙŠØ§Ø¯Ø© Ø¨Ø§Ù„Ø¯Ø®Ù„ ÙˆÙ†Ù„Ø§Ø­Ø¸ ØªÙ†Ø§ÙˆØ¨ Ø¨ÙŠÙ† ØµØ¹ÙˆØ¯ ÙˆÙ‡Ø¨ÙˆØ· ÙÙŠ Ø§Ù„Ø§ÙŠØ§Ù… ÙˆÙŠØ¹ÙˆØ¯ Ù‡Ø°Ø§ Ø§Ù„Ø§Ù…Ø± Ø§ØªÙˆÙ‚Ø¹ Ø§Ù†Ùˆ Ø´Ø®Øµ ÙŠÙ„ÙŠ Ø¨ÙŠØ±ÙƒØ¨ ÙŠÙˆÙ… Ø¨Ø±ÙŠØ­ Ø§Ù„ÙŠÙˆÙ… ÙŠÙ„ÙŠ Ø¨Ø¹Ø¯Ùˆ\n",
        "\n",
        "*   Ù„Ø¯ÙŠÙ†Ø§ Ø¨Ø´Ù‡Ø± april Ù‡Ø¨ÙˆØ· ÙˆØ§Ø¶Ø­ ÙÙŠ Ø§Ù„Ø±Ø¨Ø­ Ø§Ù„Ø³Ø¨Ø¨ Ù‚Ø¯ ÙŠØ¹ÙˆØ¯ Ø§Ù„Ù‰ Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ Ø¯Ø§ØªØ§ ÙƒØ§ÙÙŠØ© ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ø´Ù‡Ø±\n",
        "\n",
        "* Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„Ù„Ø§ÙŠØ±Ø§Ø¯Ø§Øª Ø§Ù„Ø§Ø³Ø¨ÙˆØ¹ÙŠØ© Ù…Ù„Ø§Ø­Ø¸ Ø§Ù†Ù‡ Ø¨Ø´ÙƒÙ„ Ø¹Ø§Ù… Ø§Ù„Ø§Ù…ÙˆØ± Ù†Ø­Ùˆ Ø²ÙŠØ§Ø¯Ø© Ø­ÙŠØ« Ø§Ù† Ù‡Ø°Ø§ Ø§Ù„ØªØ°Ø¨Ø°Ø¨ Ø±Ø§Ø­ Ø¨Ø³Ø¨Ø¨ Ø§Ù†Ùˆ Ø§Ù„Ø§Ø³Ø¨ÙˆØ¹ÙŠ Ø¹Ø·Ø§Ù†Ø§ Ø§Ù„Ø´ÙƒÙ„ Ø§Ù„Ø¹Ø§Ù… Ø¨Ø§Ù„Ø§Ø³Ø¨ÙˆØ¹ ÙØ§ØµØ¨Ø­ Ø®Ø·  Ø§ÙƒØ«Ø± Ø§Ù†Ø³ÙŠØ§Ø¨ÙŠØ©\n",
        "\n",
        "* Ø¨Ø´ÙƒÙ„ Ø¹Ø§Ù… ÙŠÙˆØ¬Ø¯ Ù…Ø´ÙƒÙ„Ø© ÙÙŠ Ø´Ù‡Ø± april\n",
        "\n"
      ],
      "metadata": {
        "id": "etFjRM408uj6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "Task5\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5eD0_i2uIAbd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "monthly_rev = sampled_df.groupby('start_month')['trip_cost'].mean().reset_index(name='avg_revenue')\n",
        "fig = px.line(monthly_rev, x='start_month', y='avg_revenue', title='average month income')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "m7UREu3XITUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* ÙŠØ¨ÙŠÙ† Ù„Ù†Ø§ Ø§Ù„Ù…Ø®Ø·Ø· ØªØ·ÙˆØ± Ù…ØªÙˆØ³Ø· ØªÙƒÙ„ÙØ© Ø§Ù„Ø±Ø­Ù„Ø© Ø§Ù„ÙˆØ§Ø­Ø¯Ø© Ø®Ù„Ø§Ù„ Ø´Ù‡Ø± Ø§Ù„Ø§ÙˆÙ„ ÙƒØ§Ù† Ù…ØªÙˆØ³Ø· ØªÙƒÙ„ÙØ© Ø§Ù„Ø±Ø­Ù„Ø© Ù…Ø§ ÙŠÙ‚Ø§Ø±Ø¨ 3.78 Ø¯ÙˆÙ„Ø§Ø± Ù…Ø¹ Ø¯Ø®ÙˆÙ„ Ø§Ù„Ø´Ù‡Ø± Ø§Ù„Ø«Ø§Ù†ÙŠ Ù†Ù„Ø§Ø­Ø¸ Ø§Ø±ØªÙØ§Ø¹ Ø·ÙÙŠÙ ÙˆÙŠØ³ØªÙ…Ø± Ø§Ù„Ø§Ø±ØªÙØ§Ø¹ Ø¨Ø´ÙƒÙ„ Ø·ÙÙŠÙ Ø­ØªÙ‰ Ø§Ù„Ø´Ù‡Ø± Ø§Ù„Ø«Ø§Ù„Ø« Ù‡Ø°Ø§ Ø§Ù„Ù†Ù…Ùˆ Ø§Ù„ØªØ¯Ø±ÙŠØ¬ÙŠ ÙŠÙˆØ­ÙŠ Ø¨Ø§Ù† Ø´ÙŠØ¦Ø§Ù‹ Ù…Ø§ ÙƒØ§Ù† ÙŠØªØºÙŠØ± Ø¨Ø¨Ø·Ø¡ ÙˆØ«Ø¨Ø§Øª Ø±Ø¨Ù…Ø§ ÙƒØ§Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙˆÙ† ÙŠÙ…ÙŠÙ„ÙˆÙ† Ù„Ø£Ø®Ø° Ø±Ø­Ù„Ø§Øª Ø£Ø·ÙˆÙ„ Ù‚Ù„ÙŠÙ„Ù‹Ø§ØŒ Ø£Ùˆ Ø£Ù† Ù‡Ù†Ø§Ùƒ Ø²ÙŠØ§Ø¯Ø© Ø·ÙÙŠÙØ© ÙÙŠ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¯Ø±Ø§Ø¬Ø§Øª Ø°Ø§Øª Ø§Ù„ØªÙƒÙ„ÙØ© Ø§Ù„Ø£Ø¹Ù„Ù‰ØŒ Ø£Ùˆ Ø±Ø¨Ù…Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ ØªØ²Ø§ÙŠØ¯ ÙÙŠ Ø§Ù„Ø±Ø­Ù„Ø§Øª Ø§Ù„ØªÙŠ ØªØªØ®Ø·Ù‰ Ø§Ù„Ø­Ø¯ÙˆØ¯ Ø§Ù„Ø²Ù…Ù†ÙŠØ© Ø§Ù„Ù…Ø¬Ø§Ù†ÙŠØ© Ù„Ù„Ù…Ø´ØªØ±ÙƒÙŠÙ† ÙˆØªØªØ­Ù…Ù„ Ø±Ø³ÙˆÙ…Ù‹Ø§ Ø¥Ø¶Ø§ÙÙŠØ©. Ù‡Ø°Ù‡ Ø§Ù„Ø²ÙŠØ§Ø¯Ø©ØŒ ÙˆØ¥Ù† ÙƒØ§Ù†Øª ØµØºÙŠØ±Ø©ØŒ ØªØ´ÙŠØ± Ø¥Ù„Ù‰ Ø£Ù† Ù‚ÙŠÙ…Ø© Ø§Ù„Ø±Ø­Ù„Ø© Ø§Ù„ÙˆØ§Ø­Ø¯Ø© ÙƒØ§Ù†Øª ÙÙŠ Ø§Ø²Ø¯ÙŠØ§Ø¯\n",
        "* Ø«Ù… Ù†ØµÙ„ Ø§Ù„Ù‰ Ø´Ù‡Ø± Ø§Ù„Ø±Ø§Ø¨Ø¹ Ù†Ù„Ø§Ø­Ø¸ Ù‚ÙØ²Ø© ÙÙŠ Ù…ØªÙˆØ³Ø· Ø§Ù„Ø±Ø­Ù„Ø© Ø§Ù„ÙˆØ§Ø­Ø¯Ø© Ø¨Ø´ÙƒÙ„ Ù…Ù„Ø­ÙˆØ¸ Ø­ÙŠØ« ÙˆØµÙ„ Ø§Ù„4 Ø¯ÙˆÙ„Ø§Ø± Ù…Ø³Ø¬Ù„ Ø§Ø¹Ù„Ù‰ Ù…ØªÙˆØ³Ø· Ø®Ù„Ø§Ù„ Ù‡Ø°Ù‡ Ø§Ù„ÙØªØ±Ø© Ù‚Ø¯ ÙŠØ¨Ø¯Ùˆ Ù„Ù„Ø­Ø¸Ø© Ø§Ù† Ø§Ù„Ø§Ù…Ø± Ø¬ÙŠØ¯ ÙˆÙ„ÙƒÙ† Ù…Ø¹ Ø§Ù„Ù†Ø¸Ø± Ø§Ù„Ù‰ Ù…Ø®Ø·Ø· Ø§Ù„ÙŠÙˆÙ…ÙŠ ÙˆØ§Ù„Ø§Ø³Ø¨ÙˆØ¹ÙŠ ÙÙ†Ø­Ø¯Ø¯ Ø´Ù‡Ø¯Ù†Ø§ Ù‡Ø¨ÙˆØ· ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ø´Ù‡Ø± ÙˆÙ‚Ø¯ ÙŠØ¹ÙˆØ¯ Ø³Ø¨Ø¨ Ø§Ù„Ù‡Ø¨ÙˆØ· ÙÙŠ Ø±ÙØ¹ Ø³Ø¹Ø± Ø§Ù„Ø±Ø­Ù„Ø© Ù…Ù…Ø§ Ø§Ø¯Ù‰ Ø§Ù„Ø§Ù†Ù‡ÙŠØ§Ø± Ø§Ù„Ø®Ø¯Ù…Ø© Ø§Ù†Ù‡ÙŠØ§Ø±Ø§Ù‹ ÙƒØ§Ø±Ø«ÙŠØ§Ù‹\n",
        "\n",
        "* ÙˆØ§ÙŠØ¶Ø§ Ù…Ù…ÙƒÙ† Ù‡Ø°Ø§ Ø§Ù„Ø§Ø±ØªÙØ§Ø¹ Ø§ØªÙ‰ Ø¨Ù…Ø§ Ø§Ù†Ù‡ Ø¹Ø¯Ø¯ Ø§Ù„Ø±Ø­Ù„Ø§Øª Ø§Ù„Ø§Ø¬Ù…Ø§Ù„ÙŠØ© ÙÙŠ Ø§Ù„Ø´Ù‡Ø± Ø§Ù„Ø±Ø§Ø¨Ø¹ Ù‚Ù„ÙŠÙ„Ø© ÙÙˆØ¬ÙˆØ¯ Ù‚ÙŠÙ… Ø´Ø§Ø°Ø© Ø§Ùˆ Ù…Ø±ØªÙØ¹Ø© ÙƒÙ…Ø§ Ø´Ù‡Ø¯Ù†Ø§ ÙÙŠ Ù…Ø®Ø·Ø· ÙƒÙ„Ù Ø§Ù„Ø±Ø­Ù„ Ø³ÙŠØ±ÙØ¹ Ù…ØªÙˆØ³Ø· ÙƒÙ„ÙØ© Ø§Ù„Ø±Ø­Ù„Ø© Ø¨Ù‡Ø°Ø§ Ø§Ù„Ø´ÙƒÙ„\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "# **Ø§Ù„Ø®Ù„Ø§ØµØ©**\n",
        "\n",
        "\n",
        "*   ÙƒØ§Ù†Øª Ø®Ø¯Ù…Ø© Ù…Ø´Ø§Ø±ÙƒØ© Ø§Ù„Ø¯Ø±Ø§Ø¬Ø§Øª ØªØ´Ù‡Ø¯ Ù†Ù…ÙˆÙ‹Ø§ Ù…Ø³ØªÙ…Ø±Ù‹Ø§ ÙÙŠ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø¥ÙŠØ±Ø§Ø¯Ø§ØªÙ‡Ø§ ÙˆÙÙŠ Ù‚ÙŠÙ…Ø© Ø§Ù„Ø±Ø­Ù„Ø© Ø§Ù„ÙˆØ§Ø­Ø¯Ø© Ù…Ù† ÙŠÙ†Ø§ÙŠØ± ÙˆØ­ØªÙ‰ Ù…Ù†ØªØµÙ Ù…Ø§Ø±Ø³.\n",
        "*   Ù…Ø¹ Ø°Ù„ÙƒØŒ ÙÙŠ Ø£ÙˆØ§Ø®Ø± Ù…Ø§Ø±Ø³/Ø£ÙˆØ§Ø¦Ù„ Ø£Ø¨Ø±ÙŠÙ„ØŒ Ù‚Ø¯ ØªÙƒÙˆÙ† Ø§Ù„Ø´Ø±ÙƒØ© ØªØ¹Ø±Ø¶Øª Ù„Ø­Ø¯Ø« Ø¬Ø³ÙŠÙ… (Ø¥Ù…Ø§ Ø¥ØºÙ„Ø§Ù‚ØŒ Ø£Ùˆ ØªØ¹Ù„ÙŠÙ‚ØŒ Ø£Ùˆ Ø¹Ø·Ù„ ÙƒØ¨ÙŠØ± ÙÙŠ Ø§Ù„Ù†Ø¸Ø§Ù…) Ø£Ø¯Ù‰ Ø¥Ù„Ù‰ ØªÙˆÙ‚Ù Ø´Ø¨Ù‡ ÙƒØ§Ù…Ù„ Ù„Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø±Ø­Ù„Ø§Øª ÙˆØ§Ù„Ø¥ÙŠØ±Ø§Ø¯Ø§Øª, Ø§Ùˆ Ù‚Ø¯ ÙŠÙƒÙˆÙ† Ø¨Ø³Ø¨Ø¨ Ø±ÙØ¹ Ø±Ø³ÙˆÙ… Ø§Ù„Ø±Ø­Ù„Ø©\n",
        "* Ø§Ù„Ù‚ÙØ²Ø© ÙÙŠ Ù…ØªÙˆØ³Ø· ØªÙƒÙ„ÙØ© Ø§Ù„Ø±Ø­Ù„Ø© ÙÙŠ Ø£Ø¨Ø±ÙŠÙ„ØŒ Ø¹Ù„Ù‰ Ø§Ù„Ø±ØºÙ… Ù…Ù† Ø£Ù†Ù‡Ø§ ØªØ¨Ø¯Ùˆ Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ© ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ Ø¨Ù…ÙØ±Ø¯Ù‡ØŒ Ù‡ÙŠ ÙÙŠ Ø§Ù„ÙˆØ§Ù‚Ø¹ Ù…Ø¬Ø±Ø¯ Ø§Ù†Ø¹ÙƒØ§Ø³ Ù„Ø­Ù‚ÙŠÙ‚Ø© Ø£Ù† Ø§Ù„Ø±Ø­Ù„Ø§Øª Ø§Ù„Ù‚Ù„ÙŠÙ„Ø© Ø¬Ø¯Ù‹Ø§ Ø§Ù„Ù…ØªØ¨Ù‚ÙŠØ© ÙƒØ§Ù†Øª Ù‡ÙŠ Ø§Ù„Ø£ÙƒØ«Ø± ØªÙƒÙ„ÙØ©ØŒ Ù…Ù…Ø§ ÙŠÙ„Ù‚ÙŠ Ø§Ù„Ø¶ÙˆØ¡ Ø¹Ù„Ù‰ Ø§Ù„ÙˆØ¶Ø¹ Ø§Ù„ÙƒØ§Ø±Ø«ÙŠ Ù„Ù„Ø®Ø¯Ù…Ø© ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ø´Ù‡Ø±.\n",
        "\n",
        "* Ù‚Ø¯ ÙŠÙƒÙˆÙ† Ø³Ø¨Ø¨ Ø§Ø®Ø° Ù‚Ø±Ø§Ø± Ø§Ù„Ø´Ø±ÙƒØ© Ø¨Ø±ÙØ¹ Ø§Ù†Ù‡Ø§ ÙƒØ§Ù†Øª ØªØ­Ø§ÙˆÙ„ Ø±ÙØ¹ Ø§Ù„Ø±Ø³ÙˆÙ… ÙÙŠ Ø§Ù„Ø§Ø´Ù‡Ø± Ø§Ù„Ø§ÙˆÙ„Ù‰ ÙˆÙ„ÙƒÙ† Ø¨Ø´ÙƒÙ„ Ø·ÙÙŠÙ ÙˆØ¹Ù†Ø¯Ù…Ø§ ÙˆØ¬Ø¯Øª Ø§Ù† Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª ØªØ²Ø§Ø¯ Ù‚Ø§Ù…Øª Ø¨Ù‡Ø°Ù‡ Ø§Ù„Ø±ÙØ¹Ø© Ø¸Ù†Ø§ Ù…Ù†Ù‡Ø§ Ø§Ù†Ù‡ Ø§ØµØ¨Ø­ Ù„Ø¯ÙŠÙ‡Ø§ Ù‚Ø§Ø¹Ø¯Ø© Ø¬Ù…Ø§Ù‡ÙŠØ±ÙŠØ© ÙƒØ¨ÙŠØ±Ø© ÙˆØ§Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø¨Ø§Ø²Ø¯ÙŠØ§Ø¯ Ù„ØªÙØ§Ø¬Ø¦ Ø¨Ø­ØµÙˆÙ„ Ø¹ÙƒØ³ Ø°Ù„Ùƒ ØªÙ…Ø§Ù…Ø§\n",
        "* ÙƒÙ„ Ù‡Ø°Ù‡ Ø§Ù„Ø§Ù…ÙˆØ± Ù‡ÙŠ Ù…Ø¬Ø±Ø¯ ØªÙØ³ÙŠØ±Ø§Øª Ù…Ù…ÙƒÙ†Ø©\n",
        "\n",
        "* Ù‚Ø¯ ÙŠÙƒÙˆÙ† Ø³Ø¨Ø¨ Ø§Ù„Ø§Ø±ØªÙØ§Ø¹ Ù‡Ùˆ ÙˆØ¬ÙˆØ¯ ØªØ¶Ø®Ù…\n"
      ],
      "metadata": {
        "id": "3OjvmEDuMWMX"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOP_nkSnJTVM"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "# D)\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eWjBMMLQz1C"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "Task1\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p8hGIoisQ9_F"
      },
      "outputs": [],
      "source": [
        "#Loading Residential and Visitor Parking Zones\n",
        "Residential_Visitor_Parking_Zones  = gpd.read_file('Homework/data/Residential_and_Visitor_Parking_Zones.geojson')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-fDXw62JRJl"
      },
      "outputs": [],
      "source": [
        "# Step 0: Load residential zones GeoDataFrame (assuming it's already loaded)\n",
        "res_zones = Residential_Visitor_Parking_Zones\n",
        "res_zones = res_zones.to_crs(epsg=4326)  # make sure it matches trip coordinates\n",
        "\n",
        "# Step 1: Create GeoDataFrames for start and end points\n",
        "start_gdf = gpd.GeoDataFrame(\n",
        "    sampled_df,\n",
        "    geometry=gpd.points_from_xy(sampled_df['start_lng'], sampled_df['start_lat']),\n",
        "    crs='EPSG:4326'\n",
        ")\n",
        "\n",
        "end_gdf = gpd.GeoDataFrame(\n",
        "    sampled_df,\n",
        "    geometry=gpd.points_from_xy(sampled_df['end_lng'], sampled_df['end_lat']),\n",
        "    crs='EPSG:4326'\n",
        ")\n",
        "\n",
        "# Step 2: Spatial join to check which points fall inside residential zones\n",
        "start_in_res = gpd.sjoin(start_gdf, res_zones, predicate='within', how='inner')\n",
        "end_in_res = gpd.sjoin(end_gdf, res_zones, predicate='within', how='inner')\n",
        "\n",
        "# Step 3: Extract lat/lon of trips touching residential zones\n",
        "res_start_points = start_in_res[['start_lat', 'start_lng']].rename(columns={'start_lat': 'lat', 'start_lng': 'lon'})\n",
        "res_end_points = end_in_res[['end_lat', 'end_lng']].rename(columns={'end_lat': 'lat', 'end_lng': 'lon'})\n",
        "\n",
        "# Combine both\n",
        "res_points = pd.concat([res_start_points, res_end_points], ignore_index=True)\n",
        "\n",
        "# Step 4: Count total trips that are outside residential zones (neither start nor end matched)\n",
        "trip_ids_with_res = set(start_in_res['ride_id']).union(set(end_in_res['ride_id']))\n",
        "non_res_trip_count = sampled_df[~sampled_df['ride_id'].isin(trip_ids_with_res)].shape[0]\n",
        "\n",
        "# Step 5: Plot heatmap with Plotly\n",
        "fig = px.density_mapbox(\n",
        "    res_points,\n",
        "    lat='lat',\n",
        "    lon='lon',\n",
        "    radius=10,\n",
        "    center=dict(lat=res_points['lat'].mean(), lon=res_points['lon'].mean()),\n",
        "    zoom=11,\n",
        "    mapbox_style='carto-positron',\n",
        "    title='Geographic Heatmap of Trips to Residential Zones'\n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "    margin={\"r\":0,\"t\":30,\"l\":0,\"b\":0},\n",
        "    dragmode=False\n",
        ")\n",
        "\n",
        "fig.show(config={\"staticPlot\": True})  # disables all interactivity\n",
        "\n",
        "# Step 6: Print number of trips outside residential zones\n",
        "print(f\"Total number of trips outside residential zones: {non_res_trip_count}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oZTM_ZuT-zD"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "Task2\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iY_LY76_J5iH"
      },
      "outputs": [],
      "source": [
        "# Step 1: Count trips per geohash sector\n",
        "geohash_counts = sampled_df['geohash_p6'].value_counts().reset_index()\n",
        "geohash_counts.columns = ['geohash_p6', 'trip_count']\n",
        "\n",
        "# Optional: sort alphabetically or by count\n",
        "geohash_counts = geohash_counts.sort_values(by='trip_count', ascending=False)\n",
        "\n",
        "# Step 2: Plot\n",
        "fig = px.bar(\n",
        "    geohash_counts,\n",
        "    x='geohash_p6',\n",
        "    y='trip_count',\n",
        "    title='Distribution of Trips by Geographic Sector (Geohash_p6)',\n",
        "    labels={'geohash_p6': 'Geographic Sector', 'trip_count': 'Number of Trips'}\n",
        ")\n",
        "\n",
        "# Step 3: Turn off interactivity\n",
        "fig.show(config={'staticPlot': True})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6ZXZV3XVa7n"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "Task3\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EINWUb4QUIeO"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 1. Distance to CBD\n",
        "fig1 = px.histogram(\n",
        "    sampled_df,\n",
        "    x='distance_to_cbd_m',\n",
        "    nbins=40,\n",
        "    title='Distribution of Distance to CBD (m)',\n",
        "    labels={'distance_to_cbd_m': 'Distance to CBD (meters)'}\n",
        ")\n",
        "fig1.show(config={'staticPlot': True})\n",
        "\n",
        "# 2. Closest Metro Station Distance\n",
        "fig2 = px.histogram(\n",
        "    sampled_df,\n",
        "    x='start_nearest_metro_distance',\n",
        "    nbins=30,\n",
        "    title='Distribution of Distance to Nearest Metro Station',\n",
        "    labels={'start_nearest_metro_distance': 'Distance to Metro (meters)'}\n",
        ")\n",
        "fig2.show(config={'staticPlot': True})\n",
        "\n",
        "# 3. Closest Shuttle Station Distance\n",
        "fig3 = px.histogram(\n",
        "    sampled_df,\n",
        "    x='start_nearest_shuttle_distance',\n",
        "    nbins=30,\n",
        "    title='Distribution of Distance to Nearest Shuttle Station',\n",
        "    labels={'start_nearest_shuttle_distance': 'Distance to Shuttle (meters)'}\n",
        ")\n",
        "fig3.show(config={'staticPlot': True})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "Task4\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "6Zxf96lZssHE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Categorize trips\n",
        "def classify_trip(row):\n",
        "    if row['start_in_cbd'] == 1 and row['end_in_cbd'] == 1:\n",
        "        return 'Fully in CBD'\n",
        "    else:\n",
        "        return 'Outside CBD'\n",
        "\n",
        "# Apply classification\n",
        "sampled_df['cbd_trip_type'] = sampled_df.apply(classify_trip, axis=1)\n",
        "\n",
        "# Count\n",
        "trip_cbd_counts = sampled_df['cbd_trip_type'].value_counts().reset_index()\n",
        "trip_cbd_counts.columns = ['Trip Type', 'Count']\n",
        "\n",
        "# Plot\n",
        "fig = px.bar(\n",
        "    trip_cbd_counts,\n",
        "    x='Trip Type',\n",
        "    y='Count',\n",
        "    title='Trips Fully in CBD vs Outside',\n",
        "    text='Count',\n",
        "    labels={'Count': 'Number of Trips'}\n",
        ")\n",
        "\n",
        "fig.update_traces(textposition='outside')\n",
        "fig.update_layout(yaxis_title='Number of Trips', xaxis_title='Trip Category')\n",
        "fig.show(config={'staticPlot': True})\n"
      ],
      "metadata": {
        "id": "63xLkRdqrujr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ppoVrQwUsq63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trips_df['cbd_trip_type'] = trips_df.apply(classify_trip, axis=1)\n",
        "full_trip_cbd_counts = trips_df['cbd_trip_type'].value_counts().reset_index()\n",
        "full_trip_cbd_counts.columns = ['Trip Type', 'Count']\n",
        "full_trip_cbd_counts['Percentage'] = (full_trip_cbd_counts['Count'] / full_trip_cbd_counts['Count'].sum()) * 100\n",
        "full_trip_cbd_counts"
      ],
      "metadata": {
        "id": "IoWwMMOttvP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "Task5\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "xbWLXpMNuCVn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Filter trips that passed through CBD\n",
        "cbd_passed_df = sampled_df[\n",
        "    (sampled_df['start_in_cbd'] == 1) | (sampled_df['end_in_cbd'] == 1)\n",
        "]\n",
        "\n",
        "# Group by rideable_type and member_casual\n",
        "grouped = cbd_passed_df.groupby(['rideable_type', 'member_casual']).size().reset_index(name='trip_count')\n",
        "\n",
        "# Plot\n",
        "fig = px.bar(\n",
        "    grouped,\n",
        "    x='rideable_type',\n",
        "    y='trip_count',\n",
        "    color='member_casual',\n",
        "    barmode='group',\n",
        "    title='Trips That Passed Through CBD by Rideable Type and Membership',\n",
        "    labels={'trip_count': 'Number of Trips', 'rideable_type': 'Bike Type'}\n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "    xaxis_title='Rideable Type',\n",
        "    yaxis_title='Number of Trips'\n",
        ")\n",
        "fig.show(config={'staticPlot': True})\n"
      ],
      "metadata": {
        "id": "re3aHjZmtmpv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cbd_passed_df_trips_df=trips_df[\n",
        "    (trips_df['start_in_cbd'] == 1) | (trips_df['end_in_cbd'] == 1)\n",
        "]\n",
        "\n",
        "# Group by rideable_type and member_casual\n",
        "grouped = cbd_passed_df_trips_df.groupby(['rideable_type', 'member_casual']).size().reset_index(name='trip_count')\n",
        "\n",
        "print(f\"Length of cbd_passed_df_trips_df: {len(cbd_passed_df_trips_df)}\")\n",
        "print(f\"Length of trips_df: {len(trips_df)}\")\n",
        "\n",
        "percentage = (len(cbd_passed_df_trips_df) / len(trips_df)) * 100\n",
        "print(f\"Percentage of cbd_passed_df_trips_df compared to trips_df: {percentage:.2f}%\")"
      ],
      "metadata": {
        "id": "bE6Ah0JBuxCX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "Task6\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "SUGoOn14yROg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a contingency table\n",
        "# (Counts of each combination)\n",
        "\n",
        "# Make sure weâ€™re using categorical data\n",
        "contingency_table = pd.crosstab(trips_df['close_to_cbd'], trips_df['member_casual'])\n",
        "contingency_table\n"
      ],
      "metadata": {
        "id": "YmcXeVxLv7yx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run chi-square test\n",
        "chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
        "\n",
        "print(\"Chi2 Statistic:\", chi2)\n",
        "print(\"Degrees of Freedom:\", dof)\n",
        "print(\"P-value:\", p)\n",
        "# interpretion based on the p-value:\n",
        "\n",
        "if p < 0.05:\n",
        "    print(\"âœ… There is a significant correlation between distance to CBD segments and membership type.\")\n",
        "else:\n",
        "    print(\"âŒ No significant correlation found between distance to CBD segments and membership type.\")\n"
      ],
      "metadata": {
        "id": "00075kXbydNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Î± Value  | Interpretation                                                                |\n",
        "| -------- | ----------------------------------------------------------------------------- |\n",
        "| **0.05** | Most common â€” means you're willing to accept a 5% chance of a false positive. |\n",
        "| 0.01     | Stricter â€” used in more critical fields (medicine, etc.).                     |\n",
        "| 0.10     | Looser â€” sometimes used in exploratory research.                              |\n"
      ],
      "metadata": {
        "id": "IIDvh1wlz_gr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Member trips are more common outside the CBD (proportionally).\n",
        "\n",
        "Casual riders are slightly more concentrated inside the CBD, which makes sense:\n",
        "\n",
        "Casuals may be tourists or occasional users.\n",
        "\n",
        "Members might be commuting or local residents going to/from suburban areas.\n"
      ],
      "metadata": {
        "id": "K0oXDOroztOm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "# E)\n",
        "---\n"
      ],
      "metadata": {
        "id": "tTmCrroEvV9c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "Task 1\n",
        "---"
      ],
      "metadata": {
        "id": "M7foeLjdv92S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_df.columns"
      ],
      "metadata": {
        "id": "Q612ysGB081J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_df['rideable_type'].unique()"
      ],
      "metadata": {
        "id": "k6KBbAssmo01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "daily_weather_avg = sampled_df.groupby('date')[['temp', 'humidity', 'windspeed']].mean().reset_index()\n",
        "daily_weather_avg = daily_weather_avg.rename(columns={\n",
        "    'temp': 'Average Temperature',\n",
        "    'humidity': 'Average Humidity',\n",
        "    'windspeed': 'Average Wind Speed'\n",
        "})\n",
        "fig = px.line(\n",
        "    daily_weather_avg,\n",
        "    x='date',\n",
        "    y=['Average Temperature', 'Average Humidity', 'Average Wind Speed'], # List of columns for y-axis\n",
        "    title='Average Daily Weather Conditions (Temperature, Humidity, Wind Speed)',\n",
        "    labels={\n",
        "        'date': 'Date',\n",
        "        'value': 'Average Value', # Default label for the combined y-axis values\n",
        "        'variable': 'Metric'     # Default label for the legend (which variable is which line)\n",
        "    }\n",
        ")\n",
        "fig.update_layout(hovermode=\"x unified\") # Enhances hover tooltips for multiple lines\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "shZBWnGCvY91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "Task2\n",
        "---"
      ],
      "metadata": {
        "id": "si1pOnizmFy-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "daily_weather_cond = sampled_df.groupby('date')['weather_segment'].first().reset_index()\n",
        "\n",
        "daily_rev = sampled_df.groupby(sampled_df['date'])['trip_cost'].sum().reset_index(name='revenue')\n",
        "\n",
        "merged_df = pd.merge(daily_rev, daily_weather_cond, on='date', how='left')\n",
        "fig = px.box(\n",
        "    merged_df,\n",
        "    x='weather_segment',  # Categorical variable on x-axis\n",
        "    y='revenue',      # Numerical variable on y-axis\n",
        "    title='Daily Revenue by Weather Condition',\n",
        "    labels={\n",
        "        'weather_condition': 'Weather Condition',\n",
        "        'daily_revenue': 'Daily Revenue ($)'\n",
        "    },\n",
        "    category_orders={\"weather_condition\": [\"Sunny\", \"Cloudy\", \"Rainy\"]} # Optional: ensure specific order\n",
        ")\n",
        "fig.update_traces(boxpoints='all', jitter=0.3) # Show individual points for more detail\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "Jezx6JnlOeVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Ù†Ù„Ø§Ø­Ø¸ Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„Ù„Ø§ÙŠØ§Ù… Ø§Ù„Ù…Ø§Ø·Ø±Ø© ÙŠÙ‚Ø¹ ÙˆØ³Ø·ÙŠØ§ Ø§Ù„Ø§ÙŠØ±Ø§Ø¯Ø§Øª Ø¹Ù†Ø¯ Ù…Ø§ÙŠÙ‚Ø§Ø±Ø¨ 650 Ø¯ÙˆÙ„Ø§Ø± ÙˆÙ‡Ùˆ  Ø§Ù‚Ù„  Ù…ØªÙˆØ³Ø· Ù…Ù† Ø¬Ù…ÙŠØ¹ Ø­Ø§Ù„Ø§Øª Ø·Ù‚Ø³ Ø±ØºÙ… ÙˆØ¬ÙˆØ¯ Ø¹Ø¯Ø¯ ÙƒØ¨ÙŠØ± Ù…Ù† Ø§Ù„Ø§ÙŠØ§Ù… Ù…Ø§Ø·Ø±Ø© Ù…Ø§ ÙŠÙ‚Ø§Ø±Ø¨ 55 Ø¨Ø§Ù„Ù…Ø¦Ø© Ù…Ù† Ø§Ù„Ø£ÙŠØ§Ù… Ù‡ÙŠ Ù…Ø§Ø·Ø±Ø© ÙˆÙ†Ù„Ø§Ø­Ø¸ Ù…Ø¯Ù‰ ØªÙˆØ³Ø¹ Ø§Ù„ØµÙ†Ø¯ÙˆÙ‚ ÙˆÙ‡Ø°Ø§ ÙŠØ´ÙŠØ± Ø§Ù„Ù‰ ØªÙ‚Ù„Ø¨ ÙƒØ¨ÙŠØ± ÙÙŠ Ø§Ù„Ø§ÙŠØ±Ø§Ø¯Ø§Øª ÙÙŠ Ø§Ù„Ø£ÙŠØ§Ù… Ø§Ù„Ù…Ø§Ø·Ø±Ø© ÙˆÙ…Ù„Ø§Ø­Ø¸ Ù‡Ø°Ø§ Ø­ÙŠØ« Ù„Ø¯ÙŠÙ†Ø§ Ø§ÙŠØ§Ù… Ø§Ù„Ø§ÙŠØ±Ø§Ø¯Ø§Øª ØªÙ‚Ø§Ø±Ø¨ Ø§Ù„ØµÙØ± ÙˆØ¨Ø¹Ø¶ Ù…ØªØ¬Ø§ÙˆØ²Ø© Ø§Ù„Ø§Ù„Ù ÙˆØ§Ø¹ØªÙ‚Ø¯ ÙŠØ¹ÙˆØ¯ Ø§Ù„Ø³Ø¨Ø¨ Ø§Ù„Ù‰ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù‚Ø±ÙŠØ¨Ø© Ø§Ù„Ù‰ Ø§Ù„ØµÙØ± Ù‡ÙŠ Ø§Ù„Ø§ÙŠØ§Ù… Ø°Ùˆ Ø§Ù…Ø·Ø§Ø± Ø´Ø¯ÙŠØ¯Ø© ÙˆÙ‡Ø°Ø§ Ù…Ù†Ø·Ù‚ÙŠ Ù…Ù† Ø§Ù„ØµØ¹Ø¨ Ø¹Ù†Ø¯Ù‡Ø§ Ø±ÙƒÙˆØ¨ Ø§Ù„Ø¯Ø±Ø§Ø¬Ø§Øª Ø§Ù…Ø§ Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„Ù„Ù‚ÙŠÙ… Ø§Ù„Ø¹Ø§Ù„ÙŠØ© ÙˆØ§Ø±Ø¯ Ø§Ù† Ø¨Ø¹Ø¶ Ø§Ù„Ø§ÙŠØ§Ù… Ø§Ù„Ù…Ù…Ø·Ø±Ø© ØªÙƒÙˆÙ† Ù…Ù‚Ø¨ÙˆÙ„Ø© ÙˆÙ‡Ø°Ø§ ÙŠØ¹ÙˆØ¯ Ø§Ù„Ù‰ Ø¨Ø¹Ø¶ Ø§Ù†ÙˆØ§Ø¹ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø§Ù„ØªÙŠ ØªØ³ØªÙ…Ø¹ ÙÙŠ Ø°Ù„Ùƒ Ø§Ùˆ Ø¨Ø³Ø¨Ø¨ Ø§Ù„Ø­Ø§Ø¬Ø© Ø§Ù„Ø¹Ø§Ø¬Ù„Ø© Ù„Ù„Ø¯Ø±Ø§Ø¬Ø© Ø¨Ø¯Ù„ Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø±\n",
        "*   Ù†Ù„Ø§Ø­Ø¸ Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„Ù„Ø§ÙŠØ§Ù… Ø§Ù„ØºØ§Ø¦Ù…Ø© Ù…Ø±ØªÙØ¹ ÙˆØ³Ø·ÙŠ Ø§Ù„Ø§ÙŠØ±Ø§Ø¯Ø§Øª Ù„Ù…Ø§ ÙŠÙ‚Ø§Ø±Ø¨ 800 Ø¯ÙˆÙ„Ø§Ø± Ø§ÙƒØ«Ø± Ù…Ù† Ø§Ù„Ø§ÙŠØ§Ù… Ø§Ù„Ù…Ø§Ø·Ø±Ø© ÙˆÙ†Ù„Ø§Ø­Ø¸ Ø§Ù†Ù‡ ÙŠÙˆØ¬Ø¯ Ø§Ø³ØªÙ‚Ø±Ø§Ø± ÙˆÙ„ÙŠØ³ ØªÙ‚Ù„Ø¨ Ø¨Ø§Ù„Ø§ÙŠØ±Ø§Ø¯Ø§Øª ÙˆØ§ÙŠØ¶Ø§ Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø§ÙŠØ±Ø§Ø¯Ø§Øª ÙÙŠ Ø§ÙŠØ§Ù… Ø§Ù„ØºØ§Ø¦Ù…Ø© Ø§Ù…Ø§ Ø¨Ø§Ø²Ø¯ÙŠØ§Ø¯ Ø§Ùˆ Ø§Ø³ØªÙ‚Ø±Ø§Ø± ÙˆÙ†Ù„Ø§Ø­Ø¸ Ù‚ÙØ²Ø§Øª Ø¹Ø§Ù„ÙŠØ© Ø¬Ø¯Ø§ ÙÙŠ Ø§Ù„Ø§ÙŠØ±Ø§Ø¯Ø§Øª ÙˆØ§Ø±Ø¯ Ø°Ù„Ùƒ Ø¹Ù†Ø¯ Ø¯Ø±Ø¬Ø§Øª Ø§Ù„Ø­Ø±Ø§Ø±Ø© Ø§Ù„Ù…Ø¹ØªØ¯Ù„Ø© Ø§Ù…Ø§ Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ØªØ¯Ù†ÙŠØ© Ø¬Ø¯Ø§ ÙÙ‡ÙŠ Ø§Ù…Ø§ Ø¨Ø´Ù‡Ø± Ø§Ù„Ø±Ø§Ø¨Ø¹ Ø§Ùˆ Ø§Ù†Ù‡Ø§ ÙƒØ§Ù†Øª Ø§ÙŠØ§Ù… Ø¹Ø·Ù„\n",
        "\n",
        "* Ø±ØºÙ… Ù‚Ù„Ø© Ø§Ù„Ø§ÙŠØ§Ù… Ø§Ù„Ù…Ø´Ù…Ø³Ø© Ø§Ù„Ø§ Ø§Ù†Ù†Ø§ Ù†Ø¬Ø¯ Ø§Ù† Ø§Ù„Ù†Ø§Ø³ ØªØªØ¬Ù‡ Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¯Ø±Ø§Ø¬Ø§Øª ÙˆÙ‡ÙŠ Ø§Ø¹Ù„Ù‰ Ù…ØªÙˆØ³Ø· Ø¯Ø®Ù„ ÙˆÙ…Ù„Ø§Ø­Ø¸ Ø§Ù† Ø§Ù„Ù†Ø§Ø³ ÙÙŠ Ø§Ù„Ø§ÙŠØ§Ù… Ø§Ù„Ù…Ø´Ù…Ø³Ø© ØªÙ…ÙŠÙ„ Ø§Ù„Ù‰ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¯Ø±Ø§Ø¬Ø§Øª ÙˆÙ‚Ø¯ ÙŠØ¹ÙˆØ¯ Ø°Ù„Ùƒ Ø¨Ø³Ø¨Ø¨ Ù‚Ù„Ø© Ø§Ù„Ø§ÙŠØ§Ù… Ø§Ù„Ù…Ø´Ù…Ø³Ø© Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯ ÙØ§Ù„Ù†Ø§Ø³ ØªØ­Ø¨ Ø§Ù„ØªØ¹Ø±Ø¶ Ù„Ù„Ø´Ù…Ø³ Ù„Ø°Ù„Ùƒ ØªÙØ¶Ù„ Ø¹Ù†Ø¯Ù‡Ø§ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¯Ø±Ø§Ø¬Ø§Øª Ø¨Ø§Ù„Ø§Ø¶Ø§ÙØ© Ø§Ù† Ø§Ù„Ø¬Ùˆ ÙŠÙƒÙˆÙ† Ø¬ÙŠØ¯\n",
        "\n",
        "* Ø­ÙŠØ« Ù†Ø³ØªÙ†ØªØ¬ ØªØ£Ø«ÙŠØ± Ø§Ù„Ø·Ù‚Ø³ Ø¹Ù„Ù‰ Ø³Ù„ÙˆÙƒ Ø§Ù„Ø±ÙƒØ§Ø¨ ÙŠØ¸Ù‡Ø± Ø¨ÙˆØ¶ÙˆØ­ ÙƒÙŠÙ ØªØ¤Ø«Ø± Ø­Ø§Ù„Ø© Ø§Ù„Ø·Ù‚Ø³ Ø¨Ø´ÙƒÙ„ Ù…Ø¨Ø§Ø´Ø± Ø¹Ù„Ù‰ Ø§Ù„Ø¥ÙŠØ±Ø§Ø¯Ø§Øª Ø§Ù„ÙŠÙˆÙ…ÙŠØ©ØŒ Ø­ÙŠØ« ÙŠÙØ¶Ù„ Ø§Ù„Ù†Ø§Ø³ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¯Ø±Ø§Ø¬Ø§Øª ÙÙŠ Ø§Ù„Ø·Ù‚Ø³ Ø§Ù„Ù…Ø¹ØªØ¯Ù„ ÙˆØ§Ù„Ù…Ø´Ù…Ø³ØŒ Ù…Ù…Ø§ ÙŠØ¤Ø¯ÙŠ Ø¥Ù„Ù‰ Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ø¥ÙŠØ±Ø§Ø¯Ø§ØªØŒ ÙÙŠ Ø­ÙŠÙ† Ø£Ù† Ø§Ù„Ø£ÙŠØ§Ù… Ø§Ù„Ù…Ù…Ø·Ø±Ø© Ø§Ù„Ø¹ÙƒØ³ Ø§Ù‚Ù„ Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† ÙˆØ§ÙŠØ±Ø§Ø¯Ø§Øª Ø§Ù‚Ù„\n",
        "\n",
        "* Ù„ÙƒÙ† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø´Ø§Ø°Ø© ÙÙŠ Ø¬Ù…ÙŠØ¹ Ø§Ù„ÙØ¦Ø§Øª ÙŠØ¯Ù„ Ø¹Ù„Ù‰ Ø£Ù† Ù‡Ù†Ø§Ùƒ Ø¯Ø§Ø¦Ù…Ù‹Ø§ Ø¨Ø¹Ø¶ Ø§Ù„Ø£ÙŠØ§Ù… Ø§Ù„ØªÙŠ Ù„Ø§ ØªØªØ¨Ø¹ Ø§Ù„Ù†Ù…Ø· Ø§Ù„Ø¹Ø§Ù… Ù„Ù„Ø·Ù‚Ø³ØŒ Ø³ÙˆØ§Ø¡ ÙƒØ§Ù†Øª Ø¬ÙŠØ¯Ø© Ø¨Ø´ÙƒÙ„ Ø§Ø³ØªØ«Ù†Ø§Ø¦ÙŠ Ø£Ùˆ Ø³ÙŠØ¦Ø© Ø¨Ø´ÙƒÙ„ Ø§Ø³ØªØ«Ù†Ø§Ø¦ÙŠ Ø­ÙŠØ« Ø¹Ù†Ø¯Ù‡Ø§ Ø§ØªÙˆÙ‚Ø¹ ÙŠÙˆØ¬Ø¯ Ø§Ù…ÙˆØ± Ø§Ø®Ø±Ù‰  ØªØ¯Ø®Ù„ Ø¹Ù†Ø¯Ù‡Ø§\n",
        "\n"
      ],
      "metadata": {
        "id": "bRyT5G-y2asD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "Task3\n",
        "---"
      ],
      "metadata": {
        "id": "igR_Nc1J9JMn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# lowess', 'rolling', 'ewm', 'expanding', 'ols'\n",
        "# --- Apply Min-Max Normalization to 'daily_revenue' ---\n",
        "# xi-xmin /xmax-xmin\n",
        "\n",
        "# min_revenue = daily_rev['revenue'].min()\n",
        "# max_revenue = daily_rev['revenue'].max()\n",
        "# daily_rev['normalized_daily_revenue'] = (daily_rev['revenue'] - min_revenue) / (max_revenue - min_revenue)\n",
        "\n",
        "merg = pd.merge(daily_weather_avg,daily_rev,on='date',how='left')\n",
        "\n",
        "cols_to_normalize = ['revenue', 'Average Temperature', 'Average Humidity']\n",
        "for col in cols_to_normalize:\n",
        "    min_val = merg[col].min()\n",
        "    max_val = merg[col].max()\n",
        "    # Avoid division by zero if all values are the same\n",
        "    if (max_val - min_val) != 0:\n",
        "        merg[f'normalized_{col}'] = (merg[col] - min_val) / (max_val - min_val)\n",
        "    else: # If all values are the same, normalized value is 0 (or 1, depends on convention)\n",
        "        merg[f'normalized_{col}'] = 0.0\n",
        "\n",
        "fig1 = px.scatter(merg,x='normalized_Average Temperature',y='normalized_revenue',\n",
        "                 title=\"relationship between daily income and temperature\",trendline='ols',\n",
        "                 labels={\n",
        "                   'Temperature': 'normalized_Average Daily Temperature',\n",
        "                   'daily_revenue': 'Daily Revenue ($)' }\n",
        "                 )\n",
        "fig1.show()\n",
        "\n",
        "\n",
        "fig2 = px.scatter(merg,x='normalized_Average Humidity',y='normalized_revenue',\n",
        "                 title=\"relationship between daily income and Humidity\",trendline='ols',\n",
        "                 labels={\n",
        "                   'Humidity': 'normalized_Average Daily humidity',\n",
        "                   'daily_revenue': 'Daily Revenue ($)' }\n",
        "                 )\n",
        "fig2.show()\n"
      ],
      "metadata": {
        "id": "g0BuFBl0sec0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„Ù„Ø¹Ù„Ø§Ù‚Ø© Ø¨ÙŠÙ† Ø§Ù„Ø§ÙŠØ±Ø§Ø¯Ø§Øª Ø§Ù„ÙŠÙˆÙ…ÙŠØ© ÙˆØ¯Ø±Ø¬Ø© Ø§Ù„Ø­Ø±Ø§Ø±Ø© Ù†Ù„Ø§Ø­Ø¸ ÙˆØ¬ÙˆØ¯ Ø¹Ù„Ø§ÙØ© Ø§Ø±ØªØ¨Ø§Ø· Ø®Ø·ÙŠ Ø§ÙŠØ¬Ø§Ø¨ÙŠØ© Ø­ÙŠØ« ÙÙŠ Ø¯Ø±Ø¬Ø§Øª Ø§Ù„Ø­Ø±Ø§Ø±Ø© Ø§Ù„Ù…Ù†Ø®ÙØ¶Ø© (-5 - 3) Ù†Ø±Ù‰ Ø§Ù†Ø®ÙØ§Ø¶ ÙÙŠ Ø§Ù„Ø§ÙŠØ±Ø§Ø¯Ø§Øª Ø«Ù… Ù…Ø¹ Ø§Ø²Ø¯ÙŠØ§Ø¯ Ø¯Ø±Ø¬Ø© Ø§Ù„Ø­Ø±Ø§Ø±Ø© Ù†Ù„Ø§Ø­Ø¸ Ø§Ù†Ù‡Ø§ ØªØ²Ø¯Ø§Ø¯ Ø§Ù„Ø§ÙŠØ±Ø¯Ø§Øª Ø§Ù„Ù‰ Ø§Ù† ØªØµÙ„ Ø§Ù„Ù‰ Ø­Ø¯ Ù…Ø¹ÙŠÙ† Ø«Ù… ØªØ¨Ø¯Ø¡ Ø¨Ø§Ù„Ù†Ø²ÙˆÙ„ Ø­ÙŠØ« Ø§Ø²Ø¯ÙŠØ§Ø¯ Ø¯Ø±Ø¬Ø© Ø§Ù„Ø­Ø±Ø§Ø±Ø© Ø§Ù„Ù‰ Ø¯Ø±Ø¬Ø© Ù…Ø§ ÙˆÙ‡ÙŠ 16 ÙŠØ¤Ø¯ÙŠ Ø§Ø²Ø¯ÙŠØ§Ø¯ Ø§Ù„Ø§ÙŠØ±Ø§Ø¯Ø§Øª ÙˆÙ„ÙƒÙ† Ø¨Ø¹Ø¯Ù‡Ø§ Ù†Ø±Ù‰ Ø§Ù† Ø§Ø²Ø¯ÙŠØ§Ø¯ Ø¯Ø±Ø¬Ø© Ø§Ù„Ø­Ø±Ø§Ø±Ø© Ø³ÙŠØ¤Ø¯ÙŠ Ø§Ù„Ù‰ Ø§Ù†Ø®ÙØ§Ø¶ ÙÙŠ Ø§Ù„Ø§ÙŠØ±Ø§Ø¯Ø§Øª\n",
        "\n",
        "\n",
        "* Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„Ù„Ø§Ø±ØªØ¨Ø§Ø· Ø§Ù„Ø®Ø·ÙŠ Ø¨ÙŠÙ† Ø§Ù„Ø§ÙŠØ±Ø§Ø¯Ø§Øª ÙˆØ§Ù„Ø±Ø·ÙˆØ¨Ø© Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø¹Ù„Ø§Ù‚Ø© Ø§Ø±ØªØ¨Ø§Ø· Ø®Ø·ÙŠ Ø­ÙŠØ« Ù†Ù„Ø§Ø­Ø¸ Ø¹Ù†Ø¯ Ø±Ø·ÙˆØ¨Ø© Ù…Ù†Ø®Ù‚Ø¶Ø© Ù„Ø¯ÙŠÙ†Ø§ Ø§ÙŠØ±Ø¯Ø§Ø¯Ø§Øª Ù…Ø±ØªÙØ¹Ø© ÙˆØ§ÙŠØ±Ø§Ø¯Ø§Øª ÙˆÙ…Ù†Ø®ÙØ¶Ø© ÙˆØ§Ù„Ø§Ù…Ø± Ø¹Ù„Ù‰ Ø§Ù„Ù‚ÙŠÙ… Ø§ÙŠ Ø¹Ù†Ø¯Ù…Ø§ ØªÙƒÙˆÙ† Ø§Ù„Ø±Ø·ÙˆØ¨Ø© Ù…ØªÙˆØ³Ø·Ø© Ø§Ùˆ Ø­ØªÙ‰ Ø¹Ø§Ù„ÙŠØ© Ù„Ø¯ÙŠÙ†Ø§ Ø§Ù„Ø§ÙŠØ±Ø§Ø¯Ø§Øª Ù…Ø±Ø§Øª ØªÙƒÙˆÙ† Ù…Ù†Ø®ÙØ¶Ø© ÙˆÙ…Ø±Ø§Øª ØªÙƒÙˆÙ† Ø¹Ø§Ù„ÙŠØ©"
      ],
      "metadata": {
        "id": "mh3X6Ti7GuF6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task4"
      ],
      "metadata": {
        "id": "u45Frt3lyl5X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  # 1. Create the Contingency Table\n",
        "# This table shows the observed frequencies (counts) of each unique combination\n",
        "# of weather segment and ride type.\n",
        "# Rows: weather_segment\n",
        "# Columns: rideable_type\n",
        "contingency_table = pd.crosstab(sampled_df['weather_segment'], sampled_df['rideable_type'])\n",
        "print(\"Contingency Table (Observed Frequencies):\")\n",
        "print(contingency_table)\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\") # Visual separator in output\n",
        "\n",
        "# 2. Perform the Chi-Square Test\n",
        "# The chi2_contingency function performs the statistical calculations.\n",
        "# It returns four values:\n",
        "#   - chi2: The calculated Chi-Square statistic.\n",
        "#   - p_value: The probability value (most important for interpretation).\n",
        "#   - dof: Degrees of freedom.\n",
        "#   - expected_frequencies: A 2D array of expected frequencies if the variables were independent.\n",
        "chi2, p_value, dof, expected_frequencies = chi2_contingency(contingency_table)\n",
        "\n",
        "print(f\"Chi2 Statistic: {chi2:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "print(f\"Degrees of Freedom: {dof}\")\n",
        "print(\"\\nExpected Frequencies Table:\")\n",
        "\n",
        "# Display the expected frequencies array as a DataFrame for better readability,\n",
        "# using the same indices (rows) and columns as the observed contingency table.\n",
        "print(pd.DataFrame(expected_frequencies, index=contingency_table.index, columns=contingency_table.columns))\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\") # Another visual separator\n",
        "\n",
        "\n",
        "# 3. Interpret the Results\n",
        "# Define the significance level (alpha), which is the threshold for comparing the p_value.\n",
        "# A common alpha level is 0.05 (or 5%).\n",
        "alpha = 0.05\n",
        "print(\"Interpretation of Results:\")\n",
        "if p_value < alpha:\n",
        "    # If the p-value is less than alpha, we reject the null hypothesis.\n",
        "    # The null hypothesis (H0) here is: There is no relationship between weather condition and ride type.\n",
        "    print(f\"Since the P-value ({p_value:.4f}) is less than the significance level (alpha = {alpha}),\")\n",
        "    print(\"we reject the null hypothesis (H0).\")\n",
        "    print(\"Conclusion: There is strong statistical evidence of a significant relationship between weather condition and ride type.\")\n",
        "    print(\"In other words, it appears that the distribution of ride types (or bike types) differs depending on the weather condition.\")\n",
        "    print(\"\\n* To understand this relationship further, compare the observed frequencies with the expected frequencies to identify which categories contribute most to the association.\")\n",
        "else:\n",
        "    # If the p-value is greater than or equal to alpha, we fail to reject the null hypothesis.\n",
        "    print(f\"Since the P-value ({p_value:.4f}) is greater than or equal to the significance level (alpha = {alpha}),\")\n",
        "    print(\"we fail to reject the null hypothesis (H0).\")\n",
        "    print(\"Conclusion: There is no sufficient statistical evidence to claim a significant relationship between weather condition and ride type.\")\n",
        "    print(\"In other words, it appears that the choice of ride type (or bike type) is not significantly affected by the weather condition, or any observed differences could be due to random chance.\")\n",
        "\n",
        "\n",
        "df_plot = contingency_table.reset_index().melt(id_vars='weather_segment', var_name='rideable_type', value_name='Count')\n",
        "\n",
        "# 2. Draw a Grouped Bar Chart\n",
        "fig = px.bar(\n",
        "    df_plot,\n",
        "    x='weather_segment',  # X-axis will be weather conditions\n",
        "    y='Count',            # Y-axis will be the number of rides\n",
        "    color='rideable_type',    # Different bars for each ride type within each weather condition\n",
        "    barmode='group',      # This makes the bars for each ride_type stand side-by-side\n",
        "    title='Ride Type Distribution by Weather Condition',\n",
        "    labels={\n",
        "        'weather_segment': 'Weather Condition',\n",
        "        'Count': 'Number of Rides',\n",
        "        'Ride Type': 'Ride Type'\n",
        "    },\n",
        "    category_orders={\"weather_segment\": [\"Sunny\", \"Cloudy\", \"Rainy\"]} # Optional: ensure specific order\n",
        ")\n",
        "\n",
        "fig.update_layout(xaxis_title=\"Weather Condition\", yaxis_title=\"Number of Rides\")\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "iQtcFMU1Kxgy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vrGtM8NTTRjF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "bZTfRsiq6CQa",
        "Nxjq-QmE5b9K",
        "SL1oTCjr6OFa",
        "zRUlFc1tO8QN",
        "e6HWUwZfBbaR",
        "3MC8yVG5pmu6",
        "6-inlm6X1UtR",
        "3M_uabQt6Bza",
        "Ellq2QJVzAe3",
        "PRZhifmX5KRC",
        "Fo1Nby-lsEf9",
        "ep9rr_N9s9v_"
      ],
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}